{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Health.ipynb allows to build the dataframe linking each product id to its corresponding nutrients: it is stored under the name of products_with_link_to_nutrients_df.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks / TODO:\n",
    "    -there are a few food items in MISC. TRANS\n",
    "    -add the nutrients present under different names and ids, such as: carbohydrates or carbohydrates by difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"some helper functions for the health analysis\"\"\"\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "#definition of stopwords\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "STOP_WORDS = list(set(stopwords.words('english')))\n",
    "STOP_WORDS.append('NFS')\n",
    "#Manual addition of words that we want to ignore to the Stopwords list \n",
    "to_delete = [\"added\",\"ns\",\"made\",\"eaten\",\"type\",\"all\",\"as\",\"to\",\"of\",\"shelf\",\"canned\",\"stable\",\"whole\",\"white\",\"cut\",\"whl\",\\\n",
    "             \"white\",\"bulk\",\"bag\",\"sgl\",\"srv\",\"packs\",\"sgl\",\"fs\",\"fluid\",\"frzn\",\"dinners\",\"frozen\",\"economy\",\"pouches\",\\\n",
    "             \"iws\",\"mxs\",\"dry\",\"mix\",\"pkg\",\"btl\",\"gds\",\"refrgratd\",\"multi\",\"pack\",\"entrees\",\"iqf\",\"stick\",\\\n",
    "             \"deli\",\"paper\",\"bkd\",\"total\"]\n",
    "STOP_WORDS = STOP_WORDS + to_delete\n",
    "\n",
    "#definition of foodwords\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "food = wn.synset('food.n.02')\n",
    "FOOD_WORDS = list(set([w for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()]))\n",
    "\n",
    "#We see words in the product dataset, we would like to write them out completely for clarity\n",
    "#TO ADD: SNKSCKYS/CRKR/CNDY\n",
    "to_transform = dict({\"frzn\":\"frozen\",\"refrgratd\":\"refrigerated\",\"brkfst\":\"breakfast\",\\\n",
    "                     \"whlsm\":\"wholesome\",\"crkr\":\"cracker\",\"cndy\":\"candy\",\"btl\":\"bottle\",\\\n",
    "                     \"sft\":\"soft\",\"flvrd\":\"flavored\",\"pwdr\":\"powder\",\"pnt\":\"peanut\",\"btr\":\"butter\"})\n",
    "\n",
    "def parse_words(str1): \n",
    "    \"\"\"\n",
    "    parses the string in a list of string (words) with all type of separators thanks to regexes\n",
    "    \"\"\"\n",
    "    #matches any separator and any whitespace and transforms to mathc to lower case\n",
    "    str1 = str1.lower()\n",
    "    str1 = list(filter(None,re.split(\"[\\s;&@\\/:,\\*\\.\\(\\)\\{\\}\\\\-%\\\"\\'0-9\\_]\",str1)))\n",
    "    #remove duplicate word, as there are many\n",
    "    str1 = list(dict.fromkeys(str1))\n",
    "    str1 = [i for i in str1 if ((not i in STOP_WORDS) and (len(i) > 2))]\n",
    "    str1 = [to_transform[i] if i in to_transform else i for i in str1]\n",
    "    stemmer = PorterStemmer()\n",
    "    str1 = [stemmer.stem(i) for i in str1]\n",
    "    return str1\n",
    "\n",
    "def trim_nutrient_name(temp):\n",
    "    \"\"\"\n",
    "    simplifies the names of the nutrients for easier access afterwards\n",
    "    \"\"\"\n",
    "    #matches any separator and any whitespace and transforms to match to lower case\n",
    "    temp = temp.lower()\n",
    "    temp = list(filter(None,re.split(\"[;&@\\/:,\\*\\.\\(\\)\\{\\}\\\\%\\\"\\']\",temp)))\n",
    "    #remove duplicate words, as there are many\n",
    "    temp = [i for i in temp if not i in STOP_WORDS]\n",
    "    if(temp[0] == \"fatty acids\"):\n",
    "        return str.strip(temp[0] + temp[1])\n",
    "    else:\n",
    "        return str.strip(temp[0])\n",
    "\n",
    "def get_amount(to_convert):\n",
    "    \"\"\"Returns the amount of a nutrient by taking into account the specified unit\n",
    "    \"\"\"\n",
    "    if(to_convert.unit_name == \"UG\"):\n",
    "        return to_convert.amount * 1e-6\n",
    "    elif(to_convert.unit_name == \"MG\"):\n",
    "        return to_convert.amount * 1e-3\n",
    "    else:\n",
    "        return to_convert.amount\n",
    "    \n",
    "def normalize_text(str1):\n",
    "    \"\"\"\n",
    "    simplifies the names of the foods for easier access afterwards\n",
    "    \"\"\"\n",
    "    #matches any separator and any whitespace and transforms to lower case\n",
    "    temp = re.sub(\"[;&@\\/:,\\*\\.\\(\\)\\{\\}\\\\%\\\"\\']\", ' ', str1)\n",
    "    temp = temp.lower()\n",
    "    words = temp.split()\n",
    "    words = [i for i in words if not i in STOP_WORDS]\n",
    "    temp = \" \".join(sorted(set(words), key=words.index))\n",
    "    return temp\n",
    "\n",
    "def get_allwords(serie):\n",
    "    \"\"\"\n",
    "    serie: serie containing lists of words\n",
    "    return a dataframe containing\n",
    "      - column name: name of the unique articles found in the lists of the serie\n",
    "      - column count: how many times they appear in the serie\n",
    "    \"\"\"\n",
    "    allwords = np.concatenate(serie.ravel())\n",
    "    allwords = pd.Series(allwords)\n",
    "    allwords = pd.DataFrame(allwords,columns= [\"name\"])\n",
    "    allwords.reset_index(inplace = True)\n",
    "    allwords.rename(columns = {'index':'number'},inplace = True)\n",
    "    allwords = allwords.groupby('name').count().sort_values(by = 'number',ascending = False)\n",
    "    return allwords.reset_index()\n",
    "\n",
    "def get_matches(test:list,food_list):\n",
    "    \"\"\"\n",
    "    test = list of strings to test\n",
    "    food_list: pandas dataframe linking the food article/id to the lists of words of its name\n",
    "    return all the articles whose words contain all of the words of test\n",
    "    \"\"\"\n",
    "    assert(type(test[0]) == str)\n",
    "    res = []\n",
    "    fdc_id = []\n",
    "    for word_list,id_ in food_list[[\"nut_ingredients\",\"fdc_id\"]].itertuples(index=False):\n",
    "        if all([word_test in word_list for word_test in test]):\n",
    "            res.append(word_list)\n",
    "            fdc_id.append(id_)\n",
    "    return pd.DataFrame(data={'match':res, 'fdc_id':np.array(fdc_id).astype(int)})\n",
    "\n",
    "def construct_dic_score(common_w):\n",
    "    \"\"\"\n",
    "    common_w: dataframe containing the common names btwn products and nutrition\n",
    "    In order to give a score to a word, the priority is to check if it is present in the ntds list. If it is,\n",
    "    it gets a score of 1.\n",
    "    The rest of the score is a max-normalized ratio of the occurence in the product dataset.\n",
    "    \n",
    "    return a dic where each of these common names + food_words have their score linked\n",
    "    \"\"\"\n",
    "    common_w = common_w.copy()\n",
    "    maxo = common_w.number_supermarket.max()\n",
    "    common_w.number_supermarket = common_w.number_supermarket / maxo\n",
    "    common_w.drop(columns= [\"number_nutrition\"],axis = 1,inplace = True)\n",
    "\n",
    "    food_word_df = pd.DataFrame(columns = common_w.columns)\n",
    "    food_word_df.name = pd.Series(FOOD_WORDS)\n",
    "\n",
    "    food_word_df.name = food_word_df.name.apply(parse_words)\n",
    "    food_word_df = food_word_df.explode('name')\n",
    "    food_word_df.drop_duplicates(inplace = True)\n",
    "    food_word_df.fillna(1,inplace = True)\n",
    "\n",
    "    dic_score = pd.concat([food_word_df,common_w])\n",
    "    dic_score = dic_score.rename(columns = {\"number_supermarket\":\"score\"})\n",
    "    dic_score = dic_score.groupby(\"name\").sum()\n",
    "    dic_score.sort_values('score',ascending = False)\n",
    "    dic_score = pd.Series(dic_score.score.values,index = dic_score.index).to_dict()\n",
    "    return dic_score\n",
    "\n",
    "def find_food(test,food_list, dic_score,verb = True):\n",
    "    \"\"\"\n",
    "    implementation of the graphic above\n",
    "    test = list of strings to test\n",
    "    food_list: pandas dataframe linking the food article/id to the lists of words of its name\n",
    "    return the best article's ingredient list AND fdc_id\n",
    "    \"\"\"\n",
    "    def printo(stringo,verb): \n",
    "        if verb:\n",
    "            print(stringo)\n",
    "    \n",
    "    \n",
    "    #printo(\"############# Analyzing the sample:{}###########\".format(test),verb)\n",
    "    if len(test) == 0:\n",
    "        #give up the sample\n",
    "        #printo(\"END no match was found!\",verb)\n",
    "        return [],np.nan #dummy\n",
    "    \n",
    "    matches_df = get_matches(test,food_list)\n",
    "    if matches_df.size == 0:\n",
    "        #printo(\"No Match: \",verb)\n",
    "        scores = [dic_score.get(i,0) for i in test]\n",
    "           \n",
    "        #for i,j in zip(test,scores):\n",
    "            #printo(\"word {} has score {}\".format(i,j),verb)\n",
    "        \n",
    "        armin = np.argmin(scores)\n",
    "        #printo(\"minscore:({},{}) will be deleted \\n\".format(scores[armin],test[armin]),verb)\n",
    "        \n",
    "        test = [elem for i,elem in enumerate(test) if i != armin]\n",
    "        return find_food(test,food_list,dic_score,verb)\n",
    "    \n",
    "    elif matches_df.size == 1:\n",
    "        match = matches_df.loc[0]\n",
    "        #match = matches[0]\n",
    "        printo(\"Found a single match:{}\".format(match[\"match\"]),verb)\n",
    "        return match\n",
    "    else:\n",
    "        sizes = [len(i) for i in matches_df[\"match\"]]\n",
    "        #sizes = [len(i) for i in matches]\n",
    "        minsize = np.min(sizes)\n",
    "        minsiz_matches_df = matches_df[(matches_df.match.apply(len).values) == minsize].copy()\n",
    "        #minsiz_matches_df = [i for i in matches if len(i) == minsize]\n",
    "        if minsiz_matches_df.size == 1:\n",
    "            printo(\"Single match of minsize:{}\".format(minsiz_matches.loc[0][\"match\"]),verb)\n",
    "            return minsiz_matches_df.loc[0]\n",
    "        else:\n",
    "            #printo(\"Many matches of minsize:{}\".format(minsiz_matches),verb)\n",
    "            #scores = [np.sum([dic_score.get(j,0) for j in trial]) for trial in minsiz_matches]\n",
    "            minsiz_matches_df.loc[:,\"scores\"] = [np.sum([dic_score.get(j,0) for j in trial]) for trial in minsiz_matches_df[\"match\"]]\n",
    "            \n",
    "            #for i,j in zip(minsiz_matches,scores):\n",
    "                #printo(\"{} match has {} score\".format(i,j),verb)\n",
    "            \n",
    "            #armin_imp = np.argmin(scores)\n",
    "            #printo(\"Match of smallest importance:{}\".format(minsiz_matches_df[\"scores\"].min()),verb)\n",
    "            #return minsiz_matches[armin_imp]\n",
    "            return minsiz_matches_df.loc[minsiz_matches_df.scores.idxmin()][[\"match\",\"fdc_id\"]]\n",
    "        \n",
    "        \n",
    "def get_nutrient_amount(product_id,nutrient,products_df1,food_nutrients_df1):\n",
    "    \"\"\"\n",
    "    product_id = id of product of which we want to know the nutritional info, int\n",
    "    nutrient = the nutrient of which we want to know the amount, string\n",
    "    products_df1 = the df which contains the products id\n",
    "    returns the amount of the specified nutrient contained in the specified product\n",
    "    \"\"\"\n",
    "    mask = (products_df1[\"PRODUCT_ID\"] == product_id)\n",
    "    if any(mask):\n",
    "        index = products_df1[mask].ref_fdc_id.values[0]\n",
    "        return food_nutrients_df1.loc[index,nutrient].values[0]\n",
    "    else:\n",
    "        print(\"Product not found\")\n",
    "        return 0\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
