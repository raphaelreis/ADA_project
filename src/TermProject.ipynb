{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from requests import get\n",
    "from tabulate import tabulate\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "#%aimport utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Data Acquisition](#data_acqui)\n",
    "    * [Loading](#loading)\n",
    "    * [Cleaning](#cleaning)\n",
    "        * [Transition](#c_trans)\n",
    "        * [Demographic](#c_demo)\n",
    "        * [Product](#c_prod)\n",
    "    * [Saving files](#saving)\n",
    "2. [Exploration](#exploration)\n",
    "    * [Getting sense of the data](#sense)\n",
    "        * [Feature presentation](#feat_pres)\n",
    "            * [Transition](#fp_tran)\n",
    "            * [Demographic](#fp_demo)\n",
    "            * [Product](#fp_prod)\n",
    "        * [Feature range](#ft_range)\n",
    "            * [Transition](#ft_tran)\n",
    "            * [Demographic](#ft_demo)\n",
    "            * [Product](#ft_prod)\n",
    "        * [Distributions](#distributions)\n",
    "            * [Transition](#d_tran)\n",
    "            * [Demographic](#d_demo)\n",
    "            * [Product](#d_prod)\n",
    "        * [Outliers analysis](#outliers)\n",
    "3. [Exploitation (work in progress...)](#explo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=data_acqui></a>\n",
    "# 1. Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=loading></a>\n",
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = []\n",
    "for r, d, f in os.walk('../data/dunnhumby - The Complete Journey CSV/'):\n",
    "    for file in f:\n",
    "        if '.csv' in file:\n",
    "            print(file)\n",
    "            dfList.append(pd.read_csv(os.path.join(r, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_demographic_df = dfList[5].copy()\n",
    "product_df = dfList[6].copy()\n",
    "transaction_data_df = dfList[7].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This table contains all products purchased by households within this study. Each line found in\n",
    "# this table is essentially the same line that would be found on a store receipt.\n",
    "transaction_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This table contains demographic information for a portion of households. Due to nature of the\n",
    "# data, the demographic information is not available for all households.\n",
    "hh_demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This table contains information on each product sold such as type of product, national or\n",
    "# private label and a brand identifier.\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=cleaning></a>\n",
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=c_trans></a>\n",
    "### Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction df is clean\n",
    "print(\"Is there any NaN in transaction table: %s\" %transaction_data_df.isna().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all column names\n",
    "transaction_data_df.columns = map(str.lower, transaction_data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set timestamp to the trans_time feature\n",
    "transaction_data_df.trans_time = transaction_data_df.trans_time.astype(str)\n",
    "trans_time_tmp = pd.to_datetime(transaction_data_df\\\n",
    "                                .trans_time.apply(lambda val: (4 - len(val)) * '0' + val if (len(val) < 4) else val), format='%H%M')\n",
    "transaction_data_df.trans_time = trans_time_tmp.apply(lambda x: x.time())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=c_demo></a>\n",
    "## Demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every feature but house_hold key is an object. The object type is not helpful. We\n",
    "# must cast it to categorical data.\n",
    "hh_demographic_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INCOME_DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast and set order\n",
    "hh_demographic_df['INCOME_DESC'] = hh_demographic_df['INCOME_DESC'].astype('category')\n",
    "hh_demographic_df.INCOME_DESC = hh_demographic_df.INCOME_DESC.cat.\\\n",
    "                                reorder_categories(['Under 15K', '15-24K','25-34K', '35-49K', '50-74K','75-99K', '100-124K','125-149K','150-174K', '175-199K', '200-249K', '250K+'], ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KID_CATEGORY_DESC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast and set order\n",
    "hh_demographic_df.KID_CATEGORY_DESC = hh_demographic_df.KID_CATEGORY_DESC.astype('category')\n",
    "hh_demographic_df.KID_CATEGORY_DESC.cat.reorder_categories(['1', '2', '3+', 'None/Unknown']\\\n",
    "                                                          , ordered=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOMEOWNER_DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting\n",
    "hh_demographic_df.HOMEOWNER_DESC = hh_demographic_df.HOMEOWNER_DESC.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HH_COMP_DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting\n",
    "hh_demographic_df.HH_COMP_DESC = hh_demographic_df.HH_COMP_DESC.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AGE_DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast and set order\n",
    "hh_demographic_df.AGE_DESC = hh_demographic_df.AGE_DESC.astype('category')\n",
    "hh_demographic_df.AGE_DESC.cat\\\n",
    "                    .reorder_categories(['19-24', '25-34', '35-44', '45-54', '55-64', '65+'], ordered=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOUSEHOLD_SIZE_DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast and set order\n",
    "hh_demographic_df.HOUSEHOLD_SIZE_DESC = hh_demographic_df.HOUSEHOLD_SIZE_DESC.astype('category')\n",
    "hh_demographic_df.HOUSEHOLD_SIZE_DESC.cat.reorder_categories(\\\n",
    "                        ['1', '2', '3', '4', '5+'], ordered=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MARITAL_STATUS_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast\n",
    "hh_demographic_df.MARITAL_STATUS_CODE = hh_demographic_df.MARITAL_STATUS_CODE.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic df is clean\n",
    "print(\"Is there any NaN in transaction table: %s\" %hh_demographic_df.isna().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all column names\n",
    "hh_demographic_df.columns = map(str.lower, hh_demographic_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=c_prod></a>\n",
    "## Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting\n",
    "product_df.DEPARTMENT = product_df.DEPARTMENT.astype('category')\n",
    "product_df.BRAND = product_df.BRAND.astype('category')\n",
    "product_df.COMMODITY_DESC = product_df.COMMODITY_DESC.astype('category')\n",
    "product_df.SUB_COMMODITY_DESC = product_df.SUB_COMMODITY_DESC.astype('category')\n",
    "product_df.CURR_SIZE_OF_PRODUCT = product_df.CURR_SIZE_OF_PRODUCT.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all column names\n",
    "product_df.columns = map(str.lower, product_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product df is clean\n",
    "print(\"Is there any NaN in transaction table: %s\" %product_df.isna().any().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=saving></a>\n",
    "## Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.set_index('product_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_demographic_df.set_index('household_key', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume here that a transaction is uniquely identifiied by the set of 3 features:\n",
    "# household_keay | BASKET_ID | PRODUCT_ID\n",
    "transaction_data_df.set_index(['household_key', 'basket_id', 'product_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is verified by the following test\n",
    "print(\"Transaction dataframe index is unique: %s\" % transaction_data_df.index.is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_df.to_pickle('../data/preprocessed_data/product.pkl')\n",
    "transaction_data_df.to_pickle('../data/preprocessed_data/transaction.pkl')\n",
    "hh_demographic_df.to_pickle('../data/preprocessed_data/demographic.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=exploration></a>\n",
    "# 2. Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading clean data\n",
    "product_df = pd.read_pickle('../data/preprocessed_data/product.pkl')\n",
    "transaction_df = pd.read_pickle('../data/preprocessed_data/transaction.pkl')\n",
    "transaction_df.trans_time = pd.to_datetime(transaction_df.trans_time, format='%H:%M:%S').dt.time\n",
    "demographic_df = pd.read_pickle('../data/preprocessed_data/demographic.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=sense></a>\n",
    "## Getting a sense of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=feat_pres></a>\n",
    "### Features presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some features whose sense are not easy to grasp, we give some insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_index_columns(df):\n",
    "    '''\n",
    "        Present the index and the features of the DataFrame\n",
    "    '''\n",
    "    \n",
    "    print(\"index: \", \" | \".join(list(df.index.names)))\n",
    "    print(\"features: \")\n",
    "    for idx, col in enumerate(df.columns.tolist()):\n",
    "        print(\"\\t %i) %s\" % (idx,col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=fp_tran></a>\n",
    "#### Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_index_columns(transaction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*day:*\n",
    "> from 1 to 711, corresponds to the daytime in the *two year long* study\n",
    "\n",
    "*sales_value:*\n",
    "\n",
    "> amount of dollars retailer receives from sale. It's not the price paid by the customer. If a customer use a coupon, he will pay less and the retailer will be reinboursed by the manufacturer.\n",
    "\n",
    "*retail_disc:*\n",
    "> Discount applied due to retailer's loyalty card program\n",
    "\n",
    "*coupon_disc:*\n",
    "> Discount applied due to manufacturer coupon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=fp_demo></a>\n",
    "#### Demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_index_columns(demographic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*hh_comp_desc:*\n",
    "> Household composition\n",
    "\n",
    "*kid_category_desc:*\n",
    "> Number of children present in the household. If 3 or more children is given by '3+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=fp_prod></a>\n",
    "#### Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_index_columns(product_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*curr_size_of_product:*\n",
    "> Indicates package size (not available for all products)\n",
    "\n",
    "*brand:*\n",
    "> * A *national* brand is the brand of a product that is distributed nationally under a brand name.\n",
    "> * A *private* label products are those manufactured by one company for sale under another company's brand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=ft_range></a>\n",
    "### Feature range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section expects to give a sense of the range in which our data is. For **numerical** values, we show the *minimum* and *maximum* values. For **categorical**, we present important statistics as follows: *count, unique, top, freq*. When the number of categories is not too large we also display it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=ft_tran></a>\n",
    "#### Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df.describe(exclude='category').loc[['min','max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=ft_demo></a>\n",
    "#### Demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in demographic_df:\n",
    "    print(\"%s values:\" % col)\n",
    "    print(demographic_df[col].unique().sort_values().tolist(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=ft_prod></a>\n",
    "#### Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.describe(include='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since it makes no sense to show min and max manufacturer ids, we\n",
    "# only show the number of unique manufacturers\n",
    "print(\"Unique manufacturers:\", len(np.unique(product_df.manufacturer)),\". Manufacturer type:\",product_df.manufacturer.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=distributions></a>\n",
    "### Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subsection is the most important part of the exploration. Indeed, it allows to get sense of bias, outliers, etc... Moreover, it guides the whole work giving intuition on which research question will be doable or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=d_tran></a>\n",
    "\n",
    "#### Transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time related:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, customers = np.unique(transaction_df.trans_time.sort_values(), return_counts=True)\n",
    "plt.bar(time, customers, width=30)\n",
    "plt.title(\"Transaction time histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comment:*\n",
    "> The amount of transaction reach a first *local maximum* around noon and the global maximum around 5p.m. which is intuitive. Indeed, people go shopping either during lunch time or after work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# household vs days (bias ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "transaction_df.day.hist(bins=100, ax=axes[0], density=True)\n",
    "axes[0].set_xlabel(\"days\")\n",
    "transaction_df.week_no.hist(bins=100, ax=axes[1], density=True)\n",
    "axes[1].set_xlabel(\"weeks_no\")\n",
    "plt.suptitle(\"Amount of transactions through the study time\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comment:*\n",
    "1. We see an increasing phase of transactions during the first 100 days (15 weeks). This suggests that data collection was \"on-flight\" or that data sampling was not gathered properly.\n",
    "2. Thus, we decide to build a new transaction dataframe where we cut the transactions before this date. We will us it for applications where it could potentially induce bias.\n",
    "3. A whole section will deal bias later in the the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discount related**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3)\n",
    "plt.suptitle(\"Distributions of discounts\")\n",
    "transaction_df.coupon_disc.hist(bins=100, ax=axes[0])\n",
    "axes[0].set_xlabel(\"coupon_discount ($)\")\n",
    "axes[0].set_yscale('log')\n",
    "transaction_df.retail_disc.hist(bins=100, ax=axes[1])\n",
    "axes[1].set_xlabel(\"retailer_discount($)\")\n",
    "axes[1].set_yscale('log')\n",
    "transaction_df.coupon_match_disc.hist(bins=100, ax=axes[2])\n",
    "axes[2].set_xlabel(\"coupon_match_disc($)\")\n",
    "axes[2].set_yscale('log')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comment:*\n",
    "> We observe the dicount: it is sharply distributed close to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantities related**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "plt.suptitle(\"Densities visualization for the quantity per transaction\", fontweight='bold')\n",
    "\n",
    "axes[0].hist(transaction_df.quantity, log=True, bins=20)\n",
    "axes[0].set_title(\"Quantity per transaction histogram\")\n",
    "axes[0].set_xlabel(\"quantity per transaction\")\n",
    "axes[0].set_ylabel(\"log(units)\")\n",
    "\n",
    "axes[1].boxplot(np.log(transaction_df.quantity.value_counts()))\n",
    "axes[1].set_xticks([0])\n",
    "axes[1].set_title(\"Quantity per transaction boxplot\")\n",
    "axes[1].set_ylabel(\"log(units)\")\n",
    "axes[1].set_xlabel(\"quantity per transaction\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comment:*\n",
    "1. Both figures (histogram and boxplot) show that the largest part of quantities exchange per transaction is less than 20 units.\n",
    "2. The median is really close to 1 (log10(units)) meaning that 50% of the quantity per transaction is less than 10.\n",
    "3. The boxplot shows us that there is a lot of outliers. We will investigate on that later in the outliers part. We suppose that some items are quantified differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, qty = np.histogram(transaction_df.quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sales value related:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "plt.suptitle(\"Densities visualization for the sales_value per transaction\", fontweight='bold')\n",
    "\n",
    "axes[0].hist(transaction_df.sales_value, log=True, bins=20)\n",
    "axes[0].set_title(\"Sales_value per transaction histogram\")\n",
    "axes[0].set_xlabel(\"sales_value per transaction\")\n",
    "axes[0].set_ylabel(\"log(units)\")\n",
    "\n",
    "axes[1].boxplot(np.log(transaction_df.sales_value.value_counts()))\n",
    "axes[1].set_xticks([0])\n",
    "axes[1].set_title(\"Sales_value per transaction boxplot\")\n",
    "axes[1].set_ylabel(\"log(units)\")\n",
    "axes[1].set_xlabel(\"sales_value per transaction\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comment:*\n",
    "1. The densities are similar as the quantity feature in the sense that they have similar shape with many outliers.\n",
    "2. However the whiskers from sales_value are in wider range than quantity feature.\n",
    "3. All that suggests that outliers from the quantity feature and those from sales_value are related. As stated previously, we will investigate on that later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**store id:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stores = np.unique(transaction_df.store_id.values)\n",
    "print(f\"Number of unique stores: {len(unique_stores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we want to evaluate what are the stores who have the higher amount of transactions\n",
    "transaction_per_store = transaction_df.store_id.value_counts().sort_index()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
    "plt.suptitle(\"\")\n",
    "axes[0].scatter(unique_stores, [1 for i in range(len(unique_stores))])\n",
    "axes[0].set_yticks(range(3))\n",
    "axes[0].set_title(\"Available store_id in the dataset\")\n",
    "axes[0].set_ylabel(\"y=1 => store_id present\")\n",
    "\n",
    "axes[1].bar(transaction_per_store.index, transaction_per_store.values, width=150)\n",
    "axes[1].set_title(\"Transaction count for each store_id\")\n",
    "axes[1].set_yscale('log')\n",
    "plt.xlabel(\"store_id\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*comment:*\n",
    "1. From fig1 we observe that there is two clusteres of stores id ([0, 5000], [30000, 35000]). If we assume that store_id are given from geographical position, we could say that this dataset is taken from two different regions.\n",
    "2. In this two cluster some stores have a lot of transactions and some have much less. This could suggest two main explainations:\n",
    "> * Either this is due to bad sampling routine. In this case we should be really attentive to any bias in the dataset.\n",
    "> * Or it could be the fact of different size of shopping centers and then we should simply remove small shopping centers when the application asks for it.\n",
    "> * The stores were sorted according to some criterion. We see that there are about 4 groups with differnet transaction amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=d_demo></a>\n",
    "#### Demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cat_bar(df):\n",
    "    df_cat = df.select_dtypes(include='category')\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "    cols = df_cat.columns\n",
    "    columns = 2\n",
    "    rows = len(cols) / columns + 1\n",
    "\n",
    "    for i in range(0, len(cols)):\n",
    "        ax = fig.add_subplot(rows, columns, i+1)\n",
    "        sns.countplot(data=df_cat, x=cols[i], ax=ax)\n",
    "        for tick in ax.get_xticklabels():\n",
    "            tick.set_rotation(45)\n",
    "            \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = print_cat_bar(demographic_df)\n",
    "fig.axes[1].set_xticklabels(('Married', 'Single', 'Unkown'))\n",
    "fig.suptitle(\"Bar plot for demographic categorical data\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment:*\n",
    "1. As the figures above suggest it, the typical houshold in this dataset:\n",
    "    * is between 25 and 54 years old\n",
    "    * is married\n",
    "    * has a median salary (between 35k and 74k per year)\n",
    "    * is homeowner\n",
    "    * is composed of 2 adults with few are no children\n",
    "2. An ideal data sampling would have select more uniformly the data two draw conclusion on the general population. We could find some reason to this non uniform data sampling\n",
    "    * This dataset is on marketing purpose. They wanted to target people in a wiser manner. Thus, it is likely they chose the most interesting people for them to increase their benefits **=> middle class households**\n",
    "    * They recruit people on voluntary basis and could not chose equilibrated household compositions.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=d_prod></a>\n",
    "#### Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='brand', data=product_df)\n",
    "plt.title(\"Brand type count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the amount of available products per commodity type\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.countplot(y='commodity_desc', data=product_df, order=product_df['commodity_desc'].value_counts().iloc[:30].index)\n",
    "plt.tick_params(axis='y')\n",
    "plt.title(\"Number of products per commodity type\", fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=outliers></a>\n",
    "### Outliers analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data_df[transaction_data_df['quantity']>150].join(product_df,on='product_id')['sub_commodity_desc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the outliers in the quantity is because the gasoline quantity is measured differently!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=explo></a>\n",
    "# 3. Exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Specific preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Nutrient module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Y. AND J. THIS IS FOR YOU GUYS'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1 Find out season with time anonymised data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2 Find out high rate sold product throughout the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.3 Trending products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Influence of demographic factors on shopping habits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to compare shopping amounts amongst households, we must deal with the fact that they don't purchase at the same frequency or times. We can compare the shopping rate amongst households by taking the ratio of the cummulative expenditure of a household and the number of days over which they occured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing:  \n",
    "We will append purchases, savings and days into a list per household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add two columns. One with paid price and one with total savings\n",
    "transaction_df['paid_price'] = transaction_df.sales_value+ \\\n",
    "                                    transaction_df.retail_disc+\\\n",
    "                                    transaction_df.coupon_disc+\\\n",
    "                                    transaction_df.coupon_match_disc\n",
    "\n",
    "transaction_df['total_savings'] = abs(transaction_df.retail_disc+\\\n",
    "                                           transaction_df.coupon_disc+\\\n",
    "                                           transaction_df.coupon_match_disc)\n",
    "#transaction_data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the days of purchase into a list on a single row\n",
    "days_purchased_each_house=transaction_df.groupby(['household_key','day','store_id'])['paid_price']\\\n",
    ".sum()\\\n",
    ".reset_index()\\\n",
    ".set_index('household_key')\\\n",
    ".groupby('household_key')['day'].apply(list)\n",
    "#days_purchased_each_house.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute daily paid prices and daily savings, and then turn them into a list \n",
    "transaction_val_each_house=transaction_df.groupby(['household_key','day','store_id'])['paid_price','total_savings']\\\n",
    ".sum()\\\n",
    ".reset_index()\\\n",
    ".set_index('household_key')\\\n",
    ".groupby('household_key')['paid_price','total_savings']\\\n",
    ".agg({'paid_price': lambda x: [round(i,2) for i in x.tolist()],'total_savings': lambda x: [round(i,2) for i in x.tolist()]})\n",
    "#transaction_val_each_house.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the two series on household key\n",
    "transaction_freq_df = pd.merge(transaction_val_each_house,days_purchased_each_house,\\\n",
    "                               left_on='household_key',right_on='household_key')\n",
    "transaction_freq_df['day']=transaction_freq_df['day'].apply(lambda x: np.array(x))\n",
    "transaction_freq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute purchase rate, savings rate:\n",
    "We will add up all the entries per list and divide by the days spanned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the purchase rate \n",
    "def compute_rate(df,column='paid_price'):\n",
    "    \n",
    "    #Compute cumulative sum of desired column value\n",
    "    cum_value = np.sum(df[column])\n",
    "    \n",
    "    #subtract last day from first day\n",
    "    x = np.array(df['day'])\n",
    "    \n",
    "    if (x[-1]-x[0])==0: #we filter out single days\n",
    "        value_rate = np.nan\n",
    "    \n",
    "    else:\n",
    "        value_rate = cum_value/(x[-1]-x[0])\n",
    "    \n",
    "    return value_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get purchase rate and savings rate series\n",
    "purchase_rate=transaction_freq_df.apply(lambda x: compute_rate(x,'paid_price'),axis=1)\n",
    "savings_rate = transaction_freq_df.apply(lambda x: compute_rate(x,'total_savings'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join 2 series \n",
    "rates = pd.concat([purchase_rate, savings_rate], axis=1)\n",
    "rates.columns=['purchase_rate','savings_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of purchase and savings rate:\n",
    "Let's observe the distribution of these 2 quantities to ensure there are no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observe distribution of purchase rate and savings rate\n",
    "f, (ax1, ax2) = plt.subplots(2, 1)\n",
    "purchase_rate.hist(bins=200,ax=ax1)\n",
    "savings_rate.hist(bins=200,ax=ax2)\n",
    "ax1.set_title('Purchasing Rate vs. Household')\n",
    "ax1.set_xlabel('Daily Purchasing rate ($/day)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_xlabel('Daily Savings rate ($/day)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that on a daily basis the households tend to spend about 4 dollars and save about 1 dollar. Let us now see how these quantities relate to household demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Demographic Data:\n",
    "We will look at household size, income description, and age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Household size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with demographic df, groupby household size, and compute mean and std\n",
    "demographic_df.join(rates,on='household_key').\\\n",
    "groupby('household_size_desc')['purchase_rate','savings_rate'].agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df.join(rates,on='household_key').\\\n",
    "groupby('household_size_desc')['purchase_rate','savings_rate']\\\n",
    ".describe()[('purchase_rate','count')]\\\n",
    ".rename('group sizes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the purchase rates increases slightly with household size as expected, but the standard deviations are too high to conclude a significant correlation. We most also be aware that each group size is different, but they're all larger than 50, which should be high enough.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the income description distribution is very uneven, it is not a good idea to compare averages and standard deviations. Instead, a box plot could be more revealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe only with income description purchase rate and savings rate\n",
    "r_df = demographic_df.join(rates,on='household_key')[['income_desc','purchase_rate','savings_rate']]\n",
    "r_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify order of boxes in boxplot\n",
    "order = ['250K+','200-249K','175-199K','150-174K','125-149K','100-124K','75-99K','50-74K','35-49K','25-34K','15-24K']\n",
    "order = [o for o in reversed(order)]\n",
    "#do a box plot\n",
    "f,(ax1,ax2) = plt.subplots(2,1,figsize=(10,10))\n",
    "p1=sns.stripplot(x=r_df.income_desc, y=r_df.purchase_rate, data=r_df,order=order,size=2,color='.3',ax=ax1)\n",
    "p1.set_xticklabels(p1.get_xticklabels(),rotation=45)\n",
    "p1 = sns.boxplot(x=r_df.income_desc, y=r_df.purchase_rate, data=r_df,order=order,ax=ax1)\n",
    "p1.set_ylabel('Purchase Rate ($/day)')\n",
    "p1.set_xlabel('Income Description')\n",
    "\n",
    "p2=sns.stripplot(x=r_df.income_desc, y=r_df.savings_rate, data=r_df,order=order,size=2,color='.3',ax=ax2)\n",
    "p2.set_xticklabels(p2.get_xticklabels(),rotation=45)\n",
    "p2 = sns.boxplot(x=r_df.income_desc, y=r_df.savings_rate, data=r_df,order=order,ax=ax2)\n",
    "p2.set_ylabel('Savings Rate ($/day)')\n",
    "p2.set_xlabel('Income Description')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While purchase rate seems to be correlated with income, the savings rate does not seem to vary significantly accross income groups. Moreover, we see how smaller datapoints generate a large spread in the high-income groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df.join(rates,on='household_key')\\\n",
    ".groupby('age_desc')['purchase_rate','savings_rate']\\\n",
    ".agg(['mean','std']).sort_values(('purchase_rate','mean'),ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the purchase rate peaks between the ages 35-44 and drops at 65+ years old. This is an intuitive result since at 35 most people are starting families and active workers. We observe that similar to household size, the group sizes are different but they're all larger than 50. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Top bought item per household"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll observe what kind of products are bought the most by joining the product dataframe with the transaction dataframe. Since our project will focus on food, we decided to focus on the 'grocery' department of the products, which includes all the foods and drinks. We will also look at the commodity description which is the most general description of the product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge transaction df with product df\n",
    "transaction_product_id_df = transaction_df.reset_index()[['household_key','product_id','quantity','sales_value','day']]\\\n",
    ".merge(product_df[['manufacturer','department','commodity_desc','sub_commodity_desc','curr_size_of_product']]\\\n",
    "       ,left_on='product_id',right_index=True,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out departments that contain food items\n",
    "food_df =  transaction_product_id_df[transaction_product_id_df['department']\\\n",
    "                                     .isin(['NUTRITION', 'GROCERY', 'PASTRY',\n",
    "                                     'MEAT-PCKGD', 'SEAFOOD-PCKGD','PRODUCE',\n",
    "                                     'DELI','MEAT', 'SALAD BAR','GRO BAKERY',\n",
    "                                     'FROZEN GROCERY', 'SPIRITS', 'RESTAURANT'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank items per sales value per household. \n",
    "# we take top sales-value item per household and aggregate it by count \n",
    "food_df\\\n",
    ".groupby(['household_key','commodity_desc'])[['sales_value','quantity']]\\\n",
    ".sum().sort_values(['household_key','sales_value'],ascending=False).reset_index()\\\n",
    ".groupby('household_key').first().reset_index()\\\n",
    ".groupby('commodity_desc')['household_key'].count()\\\n",
    ".sort_values(ascending=False).head(20).plot.bar(rot=90)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_title('Item of Highest Sales per Household')\n",
    "ax.set_ylabel('# households')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in the food departments, the items that have largest sales values per household are mainly soft drinks and beef. Perhaps these groups dominate because they are the most expensive per unit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 2 products per household: 2d histogram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to get top 2 highest-sales value items per household. Then mapping the unique commodity descriptions to numerical values in order to plot them in a 2d histogram. Lastly, the numerical values can be replaced with original labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 2 top sales_value item per household\n",
    "top_purchased_foods= food_df.\\\n",
    "groupby(['household_key','commodity_desc'])[['sales_value','quantity']].\\\n",
    "sum().sort_values(['household_key','sales_value'],ascending=False).reset_index().\\\n",
    "groupby('household_key').head(2).reset_index()\n",
    "top_purchased_foods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary mapping commodity desc to a numerical value for the 2d histogram\n",
    "unique_com_desc = top_purchased_foods.commodity_desc.unique()\n",
    "num_to_desc = dict(enumerate(unique_com_desc))\n",
    "desc_to_num = {v: k for k, v in num_to_desc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_purchased_foods.replace({'commodity_desc':desc_to_num},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_purchased_foods.drop(['sales_value','quantity'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_purchased_foods = pd.pivot_table(top_purchased_foods,index=['household_key'],\\\n",
    "             columns=top_purchased_foods\\\n",
    "               .groupby(['household_key'])\\\n",
    "             .cumcount().add(1),values=['commodity_desc'],aggfunc='sum')\n",
    "top_purchased_foods.columns=  top_purchased_foods.columns.map('{0[0]}{0[1]}'.format) \n",
    "top_purchased_foods.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any nans which could come from families that had single transactions with only one product\n",
    "top_purchased_foods.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "#fig, ax = plt.subplots(1,1)\n",
    "plt.figure(num=None, figsize=(25, 20), dpi=80, facecolor='w', edgecolor='k')\n",
    "# Set ticks labels for x-axis\n",
    "plt.xticks(range(np.size(unique_com_desc)),num_to_desc.values(), rotation=90)\n",
    "plt.yticks(range(np.size(unique_com_desc)),num_to_desc.values())\n",
    "ax = plt.gca()\n",
    "counts, xedges, yedges, im = ax.hist2d(top_purchased_foods.commodity_desc1, top_purchased_foods.commodity_desc2, bins=250,cmap='PuBuGn',norm=LogNorm())\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.grid(True)\n",
    "plt.title('2d Histogram of top 2 sales-value products per household')\n",
    "plt.xlabel('Top Sales-Value Product')\n",
    "plt.ylabel('2nd Top Sales-Value Product')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we see that the top products per household include soft-drinks, cheese, frozen pizza, bag snacks, beef, pork and chicken which are the top items of household. Some other products such as eggs or vegetables appear as top products in only ~10 of the 2500 households. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Predict marital status and household composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G. Obesity detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
