{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from IPython.core.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUNNHUMBY_PATH = '../data/dunnhumby - The Complete Journey CSV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jerome/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "STOP_WORDS = list(set(stopwords.words('english')))\n",
    "STOP_WORDS.append('NFS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df =  pd.read_csv(os.path.join(DUNNHUMBY_PATH,\"product.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>MANUFACTURER</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>COMMODITY_DESC</th>\n",
       "      <th>SUB_COMMODITY_DESC</th>\n",
       "      <th>CURR_SIZE_OF_PRODUCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11104</td>\n",
       "      <td>864910</td>\n",
       "      <td>1156</td>\n",
       "      <td>DRUG GM</td>\n",
       "      <td>National</td>\n",
       "      <td>DEODORANTS</td>\n",
       "      <td>ANTIPERSPIRANTS ONLY (ALL OTHE</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70979</td>\n",
       "      <td>9888724</td>\n",
       "      <td>522</td>\n",
       "      <td>DRUG GM</td>\n",
       "      <td>National</td>\n",
       "      <td>AUDIO/VIDEO PRODUCTS</td>\n",
       "      <td>AGE RESTRICTED DVD S</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88503</td>\n",
       "      <td>15800442</td>\n",
       "      <td>619</td>\n",
       "      <td>MISC. TRANS.</td>\n",
       "      <td>National</td>\n",
       "      <td>NO COMMODITY DESCRIPTION</td>\n",
       "      <td>NO SUBCOMMODITY DESCRIPTION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64718</td>\n",
       "      <td>9194124</td>\n",
       "      <td>5143</td>\n",
       "      <td>DRUG GM</td>\n",
       "      <td>National</td>\n",
       "      <td>GREETING CARDS/WRAP/PARTY SPLY</td>\n",
       "      <td>SPECIAL EVERYDAY</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88636</td>\n",
       "      <td>15801533</td>\n",
       "      <td>1407</td>\n",
       "      <td>DRUG GM</td>\n",
       "      <td>National</td>\n",
       "      <td>GREETING CARDS/WRAP/PARTY SPLY</td>\n",
       "      <td>CARDS SEASONAL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8613</td>\n",
       "      <td>843260</td>\n",
       "      <td>1046</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>COLD CEREAL</td>\n",
       "      <td>KIDS CEREAL</td>\n",
       "      <td>14.5 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12743</td>\n",
       "      <td>879578</td>\n",
       "      <td>3993</td>\n",
       "      <td>MISC. TRANS.</td>\n",
       "      <td>National</td>\n",
       "      <td>NO COMMODITY DESCRIPTION</td>\n",
       "      <td>NO SUBCOMMODITY DESCRIPTION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72941</td>\n",
       "      <td>10311778</td>\n",
       "      <td>1054</td>\n",
       "      <td>DRUG GM</td>\n",
       "      <td>National</td>\n",
       "      <td>HAIR CARE ACCESSORIES</td>\n",
       "      <td>HAIR BARRETTES TAILERS</td>\n",
       "      <td>4 CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21718</td>\n",
       "      <td>958532</td>\n",
       "      <td>1944</td>\n",
       "      <td>DRUG GM</td>\n",
       "      <td>National</td>\n",
       "      <td>HOSIERY/SOCKS</td>\n",
       "      <td>LEGGS</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21127</td>\n",
       "      <td>953101</td>\n",
       "      <td>69</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Private</td>\n",
       "      <td>CAT FOOD</td>\n",
       "      <td>CAN CATFD GOURMET/SUP PREM (GR</td>\n",
       "      <td>24/3 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55019</td>\n",
       "      <td>5818247</td>\n",
       "      <td>69</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>Private</td>\n",
       "      <td>TOMATOES</td>\n",
       "      <td>TOMATOES VINE RIPE PKG</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55811</td>\n",
       "      <td>6039759</td>\n",
       "      <td>1882</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>BAKED BREAD/BUNS/ROLLS</td>\n",
       "      <td>PREMIUM BREAD</td>\n",
       "      <td>24 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51362</td>\n",
       "      <td>2744095</td>\n",
       "      <td>69</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Private</td>\n",
       "      <td>EGGS</td>\n",
       "      <td>EGGS - LARGE</td>\n",
       "      <td>18 CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66292</td>\n",
       "      <td>9419323</td>\n",
       "      <td>5356</td>\n",
       "      <td>DRUG GM</td>\n",
       "      <td>National</td>\n",
       "      <td>VALENTINE</td>\n",
       "      <td>VALENTINE GIFTWARE/DECOR</td>\n",
       "      <td>8 INCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54595</td>\n",
       "      <td>5638789</td>\n",
       "      <td>1633</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>National</td>\n",
       "      <td>SALAD MIX</td>\n",
       "      <td>BLENDS</td>\n",
       "      <td>5 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20616</td>\n",
       "      <td>948478</td>\n",
       "      <td>69</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Private</td>\n",
       "      <td>SOFT DRINKS</td>\n",
       "      <td>MIXERS(CLUB SODA/SELTZERS)FLAV</td>\n",
       "      <td>1 LTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34373</td>\n",
       "      <td>1071746</td>\n",
       "      <td>177</td>\n",
       "      <td>DRUG GM</td>\n",
       "      <td>National</td>\n",
       "      <td>BABY FOODS</td>\n",
       "      <td>BABY JUICES</td>\n",
       "      <td>32 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21663</td>\n",
       "      <td>958008</td>\n",
       "      <td>5740</td>\n",
       "      <td>DELI</td>\n",
       "      <td>National</td>\n",
       "      <td>CHEESES</td>\n",
       "      <td>CHEESE:SPECIALTY PREPACK</td>\n",
       "      <td>8 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45390</td>\n",
       "      <td>1481161</td>\n",
       "      <td>69</td>\n",
       "      <td>MEAT</td>\n",
       "      <td>Private</td>\n",
       "      <td>BEEF</td>\n",
       "      <td>PRIMAL</td>\n",
       "      <td>3 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91373</td>\n",
       "      <td>17249765</td>\n",
       "      <td>151</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>FRZN MEAT/MEAT DINNERS</td>\n",
       "      <td>FRZN MULTI SERVE ENTREES ALL</td>\n",
       "      <td>90 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7074</td>\n",
       "      <td>829594</td>\n",
       "      <td>1722</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>FROZEN PIZZA</td>\n",
       "      <td>PIZZA/PREMIUM</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38020</td>\n",
       "      <td>1104387</td>\n",
       "      <td>1599</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>COOKIES/CONES</td>\n",
       "      <td>SPECIALTY COOKIES</td>\n",
       "      <td>14 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63896</td>\n",
       "      <td>8205620</td>\n",
       "      <td>1179</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>SALD DRSNG/SNDWCH SPRD</td>\n",
       "      <td>SEMI-SOLID SALAD DRESSING MAY</td>\n",
       "      <td>10 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52376</td>\n",
       "      <td>5554709</td>\n",
       "      <td>69</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Private</td>\n",
       "      <td>COLD CEREAL</td>\n",
       "      <td>KIDS CEREAL</td>\n",
       "      <td>32 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6918</td>\n",
       "      <td>828283</td>\n",
       "      <td>159</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>COOKIES/CONES</td>\n",
       "      <td>PREMIUM COOKIES (EX: PEPPERIDG</td>\n",
       "      <td>7.5 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69599</td>\n",
       "      <td>9802996</td>\n",
       "      <td>373</td>\n",
       "      <td>DRUG GM</td>\n",
       "      <td>National</td>\n",
       "      <td>FALL AND WINTER SEASONAL</td>\n",
       "      <td>COVERGIRL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73063</td>\n",
       "      <td>10312365</td>\n",
       "      <td>1937</td>\n",
       "      <td>DRUG GM</td>\n",
       "      <td>National</td>\n",
       "      <td>HAIR CARE ACCESSORIES</td>\n",
       "      <td>HAIR COMBS AND BRUSHES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6185</td>\n",
       "      <td>822298</td>\n",
       "      <td>1411</td>\n",
       "      <td>DRUG GM</td>\n",
       "      <td>National</td>\n",
       "      <td>HOSIERY/SOCKS</td>\n",
       "      <td>NO-NONSENSE</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51823</td>\n",
       "      <td>3655778</td>\n",
       "      <td>1251</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>SOUP</td>\n",
       "      <td>CONDENSED SOUP</td>\n",
       "      <td>10.75 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34410</td>\n",
       "      <td>1072011</td>\n",
       "      <td>2461</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>IMPORTED WINE</td>\n",
       "      <td>FRENCH WINES</td>\n",
       "      <td>750 ML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRODUCT_ID  MANUFACTURER    DEPARTMENT     BRAND  \\\n",
       "11104      864910          1156       DRUG GM  National   \n",
       "70979     9888724           522       DRUG GM  National   \n",
       "88503    15800442           619  MISC. TRANS.  National   \n",
       "64718     9194124          5143       DRUG GM  National   \n",
       "88636    15801533          1407       DRUG GM  National   \n",
       "8613       843260          1046       GROCERY  National   \n",
       "12743      879578          3993  MISC. TRANS.  National   \n",
       "72941    10311778          1054       DRUG GM  National   \n",
       "21718      958532          1944       DRUG GM  National   \n",
       "21127      953101            69       GROCERY   Private   \n",
       "55019     5818247            69       PRODUCE   Private   \n",
       "55811     6039759          1882       GROCERY  National   \n",
       "51362     2744095            69       GROCERY   Private   \n",
       "66292     9419323          5356       DRUG GM  National   \n",
       "54595     5638789          1633       PRODUCE  National   \n",
       "20616      948478            69       GROCERY   Private   \n",
       "34373     1071746           177       DRUG GM  National   \n",
       "21663      958008          5740          DELI  National   \n",
       "45390     1481161            69          MEAT   Private   \n",
       "91373    17249765           151       GROCERY  National   \n",
       "7074       829594          1722       GROCERY  National   \n",
       "38020     1104387          1599       GROCERY  National   \n",
       "63896     8205620          1179       GROCERY  National   \n",
       "52376     5554709            69       GROCERY   Private   \n",
       "6918       828283           159       GROCERY  National   \n",
       "69599     9802996           373       DRUG GM  National   \n",
       "73063    10312365          1937       DRUG GM  National   \n",
       "6185       822298          1411       DRUG GM  National   \n",
       "51823     3655778          1251       GROCERY  National   \n",
       "34410     1072011          2461       GROCERY  National   \n",
       "\n",
       "                       COMMODITY_DESC              SUB_COMMODITY_DESC  \\\n",
       "11104                      DEODORANTS  ANTIPERSPIRANTS ONLY (ALL OTHE   \n",
       "70979            AUDIO/VIDEO PRODUCTS            AGE RESTRICTED DVD S   \n",
       "88503        NO COMMODITY DESCRIPTION     NO SUBCOMMODITY DESCRIPTION   \n",
       "64718  GREETING CARDS/WRAP/PARTY SPLY                SPECIAL EVERYDAY   \n",
       "88636  GREETING CARDS/WRAP/PARTY SPLY                  CARDS SEASONAL   \n",
       "8613                      COLD CEREAL                     KIDS CEREAL   \n",
       "12743        NO COMMODITY DESCRIPTION     NO SUBCOMMODITY DESCRIPTION   \n",
       "72941           HAIR CARE ACCESSORIES          HAIR BARRETTES TAILERS   \n",
       "21718                   HOSIERY/SOCKS                           LEGGS   \n",
       "21127                        CAT FOOD  CAN CATFD GOURMET/SUP PREM (GR   \n",
       "55019                        TOMATOES          TOMATOES VINE RIPE PKG   \n",
       "55811          BAKED BREAD/BUNS/ROLLS                   PREMIUM BREAD   \n",
       "51362                            EGGS                    EGGS - LARGE   \n",
       "66292                       VALENTINE        VALENTINE GIFTWARE/DECOR   \n",
       "54595                       SALAD MIX                          BLENDS   \n",
       "20616                     SOFT DRINKS  MIXERS(CLUB SODA/SELTZERS)FLAV   \n",
       "34373                      BABY FOODS                     BABY JUICES   \n",
       "21663                         CHEESES        CHEESE:SPECIALTY PREPACK   \n",
       "45390                            BEEF                          PRIMAL   \n",
       "91373          FRZN MEAT/MEAT DINNERS    FRZN MULTI SERVE ENTREES ALL   \n",
       "7074                     FROZEN PIZZA                   PIZZA/PREMIUM   \n",
       "38020                   COOKIES/CONES               SPECIALTY COOKIES   \n",
       "63896          SALD DRSNG/SNDWCH SPRD   SEMI-SOLID SALAD DRESSING MAY   \n",
       "52376                     COLD CEREAL                     KIDS CEREAL   \n",
       "6918                    COOKIES/CONES  PREMIUM COOKIES (EX: PEPPERIDG   \n",
       "69599        FALL AND WINTER SEASONAL                       COVERGIRL   \n",
       "73063           HAIR CARE ACCESSORIES          HAIR COMBS AND BRUSHES   \n",
       "6185                    HOSIERY/SOCKS                     NO-NONSENSE   \n",
       "51823                            SOUP                  CONDENSED SOUP   \n",
       "34410                   IMPORTED WINE                    FRENCH WINES   \n",
       "\n",
       "      CURR_SIZE_OF_PRODUCT  \n",
       "11104                       \n",
       "70979                       \n",
       "88503                       \n",
       "64718                       \n",
       "88636                       \n",
       "8613               14.5 OZ  \n",
       "12743                       \n",
       "72941                 4 CT  \n",
       "21718                       \n",
       "21127              24/3 OZ  \n",
       "55019                       \n",
       "55811                24 OZ  \n",
       "51362                18 CT  \n",
       "66292               8 INCH  \n",
       "54595                 5 OZ  \n",
       "20616                1 LTR  \n",
       "34373                32 OZ  \n",
       "21663                 8 OZ  \n",
       "45390                 3 LB  \n",
       "91373                90 OZ  \n",
       "7074                        \n",
       "38020                14 OZ  \n",
       "63896                10 OZ  \n",
       "52376                32 OZ  \n",
       "6918                7.5 OZ  \n",
       "69599                       \n",
       "73063                       \n",
       "6185                        \n",
       "51823             10.75 OZ  \n",
       "34410               750 ML  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.sample(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We only take the categories which are food related, sorted manually the different departments_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_sorted = products_df.groupby('DEPARTMENT').count().sort_values(by = 'PRODUCT_ID',ascending = False)\n",
    "#NB: there are a few food in MISC. TRANS\n",
    "food_related = np.array(['NUTRITION','GROCERY','PASTRY','MEAT-PCKGD','SEAFOOD-PCKGD','PRODUCE','DELI','MEAT','SALAD BAR','GRO BAKERY','FROZEN GROCERY','SPIRITS','RESTAURANT',''])\n",
    "\n",
    "products_df = products_df[products_df.DEPARTMENT.isin(food_related)]\n",
    "\n",
    "#we put all the description in a ingredients column\n",
    "products_df['ingredients'] = products_df.COMMODITY_DESC + \" \" + products_df.SUB_COMMODITY_DESC\n",
    "products_df.drop([\"MANUFACTURER\",\"DEPARTMENT\",\"BRAND\",\"COMMODITY_DESC\",\"SUB_COMMODITY_DESC\"],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(str1): \n",
    "    \"\"\"\n",
    "    pars the string in a list of string (words) with all type of separators thx to regex\n",
    "    \"\"\"\n",
    "    #matches any separator and any whitespace and transforms to mathc to lower case\n",
    "    temp = list(filter(None,re.split(\"[\\s;&@\\/:,\\*\\.\\(\\)\\{\\}\\\\-%\\\"\\'0-9]\",str1)))\n",
    "    #remove duplicate word, as there are many\n",
    "    temp = list(dict.fromkeys(temp))\n",
    "    temp = [i.lower() for i in temp if not i in STOP_WORDS]\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.ingredients = products_df.ingredients.apply(parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloaded food nutrients data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerome/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/jerome/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dfList = {}\n",
    "for r, d, f in os.walk('../data/health'):\n",
    "    for file in f:\n",
    "        if '.csv' in file:\n",
    "            #print(file)\n",
    "            dfList[file] = pd.read_csv(os.path.join(r, file))\n",
    "            \n",
    "branded_food_df = dfList['branded_food.csv']\n",
    "\n",
    "#link the nutrient id with its name\n",
    "nutrient_df = dfList['nutrient.csv']\n",
    "\n",
    "#contains the food articles name and their id test commit\n",
    "food_df = dfList['food.csv']\n",
    "\n",
    "#contains the nutrients for each food article\n",
    "food_nutrients_df = dfList['food_nutrient.csv']\n",
    "\n",
    "# linke the food articles ids to their potential category\n",
    "food_category_df = dfList['food_category.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We drop useless columns_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns and rename to be more understandable\n",
    "food_nutrients_df = food_nutrients_df.drop([\"data_points\",\"min\",\"max\",\"median\",\"footnote\",\"min_year_acquired\",\"derivation_id\"],axis=1)\n",
    "\n",
    "nutrient_df = nutrient_df.drop([\"nutrient_nbr\",\"rank\"],axis=1)\n",
    "\n",
    "food_category_df.drop([\"code\"],axis=1,inplace=True)\n",
    "food_category_df.rename(columns={'id':'food_category_id','description':'category'},inplace= True)\n",
    "\n",
    "food_df.drop([\"publication_date\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Add the names of the nutrients to the nutrients per food_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nutrients_df = food_nutrients_df.join(nutrient_df.set_index('id'),on='nutrient_id',how='left')\n",
    "\n",
    "#index the resulting table by multiindex: product id -> name of nutrients\n",
    "food_nutrients_df = food_nutrients_df.set_index(pd.MultiIndex.from_frame(food_nutrients_df[['fdc_id','name']]))\n",
    "#drop unnecessary columns \n",
    "food_nutrients_df = food_nutrients_df.drop([\"id\",\"fdc_id\",\"nutrient_id\",\"name\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We add the food category to food_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df = food_df.join(food_category_df.set_index(\"food_category_id\"),on=\"food_category_id\",how=\"left\")\n",
    "food_df.drop([\"food_category_id\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_name = food_df.copy()\n",
    "food_name.description = food_name.description.apply(parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_At this stage we have 3 dataframes for nutrition:_\n",
    "- food_df = id of food articel vs food title (string)\n",
    "- food_name_df = id of food vs parsed food title (list of string)\n",
    "- food_nutrients_df = id of food article vs food nutrients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We filter the words according to their importance: that is, a word is more important as it apears many times in both datasets: (Ex: 'orange' is more important than 'artificial'). The words occuring in only one dataset are of no importance. The rest of the algorithm follows the following pipeline:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'untitled2.svg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d8444c0fabbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'untitled2.svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'untitled2.svg'"
     ]
    }
   ],
   "source": [
    "SVG(filename='untitled2.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_allwords(serie):\n",
    "    \"\"\"\n",
    "    serie: serie containing lists of words\n",
    "    return a dataframe containing\n",
    "      - column name: name of the unique articles found in the lists of the serie\n",
    "      - column count: how many times they appear in the serie\n",
    "    \"\"\"\n",
    "    allwords = np.concatenate(serie.ravel())\n",
    "    allwords = pd.Series(allwords)\n",
    "    allwords = pd.DataFrame(allwords,columns= [\"name\"])\n",
    "    allwords.reset_index(inplace = True)\n",
    "    allwords.rename(columns = {'index':'number'},inplace = True)\n",
    "    allwords = allwords.groupby('name').count().sort_values(by = 'number',ascending = False)\n",
    "    return allwords.reset_index()\n",
    "\n",
    "#all words present in the nutrition dataset\n",
    "all_words_nut = get_allwords(food_name.description)\n",
    "\n",
    "#all words present in the product dataset\n",
    "all_words_art = get_allwords(products_df.ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Manual updates of STOPWORDS: _the idea would be to create a list of the words to update/ modify in the STOPWORDS list._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to delete\n",
    "to_delete = [\"added\",\"ns\",\"made\",\"eaten\",\"type\",\"all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to transform\n",
    "#SNKS/CKYS/CRKR/CNDY \t\n",
    "to_transform = dict({\"frzn\":\"frozen\",\"refrgratd\":\"refrigerated\",\"brkfst\":\"breakfast\",\"whlsm\":\"wholesome\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner join between the 2 sets of words:\n",
    "\n",
    "_we check which words occur in both dataframes: only these words will have importance in determining the type of food article we are dealing with. Of course, if no words are known from the nutrition dataset, the sample is not taken into account._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = pd.merge(all_words_art,all_words_nut,left_on = 'name',right_on = 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3141"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words.head(100)\n",
    "common_words.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM: the 2 dataframes don't share much words!\n",
    "possible solutions:\n",
    "- use another/more nutrition datset\n",
    "- parse better the articles dataset (some words are badly parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Manual check to see which words occur in which dataset\n",
    "print('chocolate' in all_words_nut.name.values)\n",
    "print('chocolate' in all_words_art.name.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble them together (and pray your god)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_matches(test,food_list):\n",
    "    \"\"\"\n",
    "    test = list of strings to test\n",
    "    food_list: pandas dataframe linking the food article/id to the lists of words of its name\n",
    "    return all the articles whose words contain all of the words of test\n",
    "    \"\"\"\n",
    "    raise NotImplemented\n",
    "    \n",
    "def get_importance(word):\n",
    "    \"\"\"\n",
    "    word: string for which we want to know the  importance\n",
    "    return importance of word\n",
    "    \"\"\"\n",
    "    raise NotImplemented\n",
    "    \n",
    "def find_food(test,food_list):\n",
    "    \"\"\"\n",
    "    implementation of the graphic above\n",
    "    test = list of strings to test\n",
    "    food_list: pandas dataframe linking the food article/id to the lists of words of its name\n",
    "    return the best article\n",
    "    \"\"\"\n",
    "    if len(k) == 0:\n",
    "        #give up the sample\n",
    "        return 0 #dummy\n",
    "    \n",
    "    matches = get_matches(test,food_list)\n",
    "    if len(matches) == 0:\n",
    "        importance = [get_importance(i) for i in test]\n",
    "        mino = np.min(importance)\n",
    "        test = [i for i in test if i != mino]\n",
    "        return find_food(test,food_list)\n",
    "    elif len(matches) == 1:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        sizes = [len(i) for i in matches]\n",
    "        minsize = np.min(sizes)\n",
    "        minsizes = [i for i in matches if len(i) == minsize]\n",
    "        if len(minsizes) == 1:\n",
    "            return minsizes[0]\n",
    "        else:\n",
    "            importances = [np.sum([get_importance(j) for j in trial]) for trial in minsizes]\n",
    "            armin_imp = np.argmin(importances)\n",
    "            return importances[armin_imp]\n",
    "                \n",
    "\n",
    "def find_food_naive(test,food_list):\n",
    "    \"\"\"\n",
    "    food_list: pandas dataframe linking the food article/id id to the lists of words of its name\n",
    "    test: list of strings you want to have an id for\n",
    "    return the corresponding food indx\n",
    "    \"\"\"\n",
    "    #TODO: improve the non unique max\n",
    "    scores = [get_score(test,i) for i in food_list.description]\n",
    "    maxo = np.max(scores)\n",
    "    if len([1 for x in scores if x == maxo]) > 1:\n",
    "        print(\"Multiple maximums!\")\n",
    "    armax = np.argmax(scores)\n",
    "    print('result: ',food_list.description[armax])\n",
    "    return food_list.fdc_id[armax]\n",
    "\n",
    "def get_score(test,trial):\n",
    "    \"\"\"\n",
    "    test: the list of strings you're trying to classify\n",
    "    trial: the list you want the score for\n",
    "    return the score of matching\n",
    "    \"\"\"\n",
    "    return np.sum([1 for i in test if i in trial])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple maximums!\n",
      "result:  Paella with seafood\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "338359"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = ['seafood']\n",
    "find_food_naive(test1,food_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2712"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_art.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50496"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_nut.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
