{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from IPython.core.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, './utilities/')\n",
    "\n",
    "from health_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUNNHUMBY_PATH = '../data/dunnhumby - The Complete Journey CSV/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = {}\n",
    "for r, d, f in os.walk(DUNNHUMBY_PATH):\n",
    "    for file in f:\n",
    "        if '.csv' in file:\n",
    "            print(file)\n",
    "            dfList[file] = pd.read_csv(os.path.join(r, file))\n",
    "            \n",
    "products_df = dfList['product.csv']\n",
    "transaction_data_df = dfList['transaction_data.csv']\n",
    "hh_demographic_df = dfList['hh_demographic.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We only take the categories which are food related, sorted manually the different departments_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_sorted = products_df.groupby('DEPARTMENT').count().sort_values(by = 'PRODUCT_ID',ascending = False)\n",
    "#NB: there are a few food in MISC. TRANS\n",
    "food_related = np.array(['NUTRITION','GROCERY','PASTRY','MEAT-PCKGD','SEAFOOD-PCKGD','PRODUCE','DELI','MEAT','SALAD BAR','GRO BAKERY','FROZEN GROCERY','SPIRITS','RESTAURANT',''])\n",
    "\n",
    "products_df = products_df[products_df.DEPARTMENT.isin(food_related)]\n",
    "\n",
    "#we put all the description in a ingredients column\n",
    "products_df['ingredients'] = products_df.COMMODITY_DESC + \" \" + products_df.SUB_COMMODITY_DESC\n",
    "products_df.drop([\"MANUFACTURER\",\"DEPARTMENT\",\"BRAND\",\"COMMODITY_DESC\",\"SUB_COMMODITY_DESC\"],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.ingredients = products_df.ingredients.apply(parse_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.ingredients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we now have an easily parseable format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloaded food nutrients data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = {}\n",
    "for r, d, f in os.walk('../data/health'):\n",
    "    for file in f:\n",
    "        if '.csv' in file:\n",
    "            #print(file)\n",
    "            dfList[file] = pd.read_csv(os.path.join(r, file))\n",
    "            \n",
    "branded_food_df = dfList['branded_food.csv']\n",
    "\n",
    "#link the nutrient id with its name\n",
    "nutrient_df = dfList['nutrient.csv']\n",
    "\n",
    "#contains the food articles name and their id test commit\n",
    "food_df = dfList['food.csv']\n",
    "\n",
    "#contains the nutrients for each food article\n",
    "food_nutrients_df = dfList['food_nutrient.csv']\n",
    "\n",
    "# linke the food articles ids to their potential category\n",
    "food_category_df = dfList['food_category.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We drop useless columns_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns and rename to be more understandable\n",
    "food_nutrients_df = food_nutrients_df.drop([\"data_points\",\"min\",\"max\",\"median\",\"footnote\",\"min_year_acquired\",\"derivation_id\"],axis=1)\n",
    "\n",
    "nutrient_df = nutrient_df.drop([\"nutrient_nbr\",\"rank\"],axis=1)\n",
    "\n",
    "food_category_df.drop([\"code\"],axis=1,inplace=True)\n",
    "food_category_df.rename(columns={'id':'food_category_id','description':'category'},inplace= True)\n",
    "\n",
    "food_df.drop([\"publication_date\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out only the necessary food nutrients since we have 227, a lot of which aren't necessary to determine if a food is healthy\n",
    "list_relevant_nutrients = [\"Protein\", \"Total Carbohydrate\",\"Total lipid (fat)\",\"Sucrose\",\\\n",
    "                            \"Glucose (dextrose)\",\"Sugars, total including NLEA\",\"Fatty acids, total monounsaturated\",\\\n",
    "                            \"Fatty acids, total polyunsaturated\",\"Fatty acids, total trans\",\"Fatty acids, total saturated\",\"Cholesterol\",\\\n",
    "                            \"Vitamin E, added\",\"Vitamin K (phylloquinone)\",\"Vitamin B-12\",\"Vitamin B-6\",\\\n",
    "                            \"Vitamin E (label entry primarily)\",\"Vitamin E (alpha-tocopherol)\",\"Vitamin D\",\"Vitamin A, RAE\",\"Sodium, Na\",\\\n",
    "                            \"Total fat (NLEA)\",\"Fiber, total dietary\",\"Energy\",\"Carbohydrate, by summation\",\"Fructose\"]\n",
    "\n",
    "nutrient_df = nutrient_df[nutrient_df.name.isin(list_relevant_nutrients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_df.name = nutrient_df.name.apply(trim_nutrient_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nutrients_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Add the names of the nutrients to the nutrients per food_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nutrients_df = food_nutrients_df.join(nutrient_df.set_index('id'),on='nutrient_id',how='inner')\n",
    "\n",
    "#index the resulting table by multiindex: product id -> name of nutrients\n",
    "food_nutrients_df = food_nutrients_df.set_index(pd.MultiIndex.from_frame(food_nutrients_df[['fdc_id','name']]))\n",
    "#drop unnecessary columns \n",
    "food_nutrients_df = food_nutrients_df.drop([\"id\",\"fdc_id\",\"nutrient_id\",\"name\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nutrients_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is the result\n",
    "food_nutrients_df.loc[336079,\"energy\"][\"amount\"].values[0] #TOTRASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we show the food contents of corned beef, the format matches our needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We add the food category to food_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df = food_df.join(food_category_df.set_index(\"food_category_id\"),on=\"food_category_id\",how=\"left\")\n",
    "food_df.drop([\"food_category_id\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_information_df = food_nutrients_df.join(food_df.set_index(\"fdc_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a lot of categories are unfortunately missing from the governement database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.description = food_df.description.apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, we create the dataframe that will allow us to link the test values to the one of the supermarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_name_df = food_df.copy()\n",
    "food_name_df.description = food_name_df.description.apply(parse_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_At this stage we have 3 dataframes from our additional dataset for nutrition:_\n",
    "- food_df = fdc_id vs name of food item (string)\n",
    "- food_name_df = fdc_id vs parsed food title (**list of string**)\n",
    "- food_nutrients_df = fdc_id vs nutrients contained (multiindex)\n",
    "- all_information_df = fdc_id, nutrients, data type, description and food category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We filter the words according to their importance: that is, a word is more important as it apears many times in both datasets: (Ex: 'orange' is more important than 'artificial'). The words occuring in only one dataset are of no importance. The rest of the algorithm follows the following pipeline:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(filename='graphs/allwords.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all words present in the nutrition dataset\n",
    "all_words_nutrition = get_allwords(food_name_df.description)\n",
    "\n",
    "#all words present in the product dataset\n",
    "all_words_supermarket = get_allwords(products_df.ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner merge between the 2 sets of words:\n",
    "\n",
    "_we check which words occur in both dataframes: only these words will have importance in determining the type of food article we are dealing with. Of course, if no words are known from the nutrition dataset, the sample is not taken into account._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = pd.merge(all_words_supermarket,all_words_nutrition,left_on = 'name',right_on = 'name',suffixes=('_supermarket', '_nutrition'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(common_words.size)\n",
    "common_words.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble them together (and pray your god)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(filename='graphs/Word_importance.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0 = ['duck','creamy','swiss','miss','pudding','24','oz']\n",
    "test1 = [\"penguin\",\"afdadf\"]\n",
    "test2 = [\"peanuts\",\"orange\",\"crisp\"]\n",
    "test3 = [\"sandwich\",\"lettuce\",\"cheese\"]\n",
    "test4 = [\"indian\",\"lamb\",\"josh\"]\n",
    "test5 = ['vanilla','creamy','swiss','miss','pudding','24','oz']\n",
    "test6 = ['libbys']\n",
    "test7 = [\"hispanic\", \"oriental\", \"noodles\",\" rice\"]\n",
    "test8 = [\"vegetables\", \"others\"]\n",
    "test9 = [\"frozen\", \"ice\", \"cream\", \"bars\"]\n",
    "test10 =[\"wolf\", \"chili\", \"without\", \"beans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIC_SCORE = construct_dic_score(common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df_short = products_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#First test on sample\n",
    "estimated_df = products_df_short.copy()\n",
    "findfoodshort = lambda list_words: find_food(list_words,food_name_df,DIC_SCORE,verb = True)\n",
    "estimated_df[\"ref_fdc_id\"] = products_df_short.ingredients.apply(findfoodshort).fdc_id\n",
    "estimated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full df\n",
    "estimated_total_df = products_df.copy()\n",
    "findfoodtotal = lambda list_words: find_food(list_words,food_name_df,DIC_SCORE,verb = True)\n",
    "#estimated_df[\"ref_fdc_id\"] = products_df.ingredients.apply(findfoodtotal).fdc_id\n",
    "estimated_df.head()\n",
    "#Problem: takes more than 45 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves results of this lengthy computation\n",
    "estimated_df.to_pickle(\"../data/results/products_with_link_to_nutrients_df.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have established the link between the dunnhumby supermarket dataset and the food database from the Department of Food and Agriculture which provides the nutrients information. We can now begin our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nutrient_per_day_per_person(key1,nutrient):\n",
    "    \"\"\"\n",
    "    key = household key\n",
    "    nutrient = nutrient for which we want to calculate the amount bought\n",
    "    returns the amount of a specified nutrient bought and presumably consumed per day and per person on avergade\n",
    "    in the selected household\n",
    "    \"\"\"\n",
    "    household_transactions_df = transaction_data_df[transaction_data_df.household_key == key1]\n",
    "    household_transactions_df[nutrient] = household_transactions_df[\"PRODUCT_ID\"].apply(get_nutrient_amount,args=(nutrient,))\n",
    "    time_interval = household_transactions_df[\"DAY\"].max() - household_transactions_df[\"DAY\"].min() + 1\n",
    "    nutrient_per_household = household_transactions_df[nutrient].sum() / time_interval\n",
    "    household_demographics = hh_demographic_df[hh_demographic_df.household_key == key1]\n",
    "    nutrient_per_person = nutrient_per_household / household_demographics[\"HOUSEHOLD_SIZE_DESC\"]\n",
    "    return nutrient_per_person\n",
    "\n",
    "def parse_sex_homeowner(key):\n",
    "    str1 = hh_demographic_df[hh_demographic_df.household_key == key][\"HH_COMP_DESC\"].values[0]\n",
    "    str1 = str1.lower()\n",
    "    if str1.contains(\"female\"):\n",
    "            return \"f\"\n",
    "    elif str1.contains(\"male\"):\n",
    "            return \"m\"\n",
    "    else:\n",
    "            return \"unknown\"\n",
    "    \n",
    "#TO DO\n",
    "#caloric needs adult = 2000 kcal , kid = 1000 kcal -> take it into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nutrient_amount(25671,\"energy\",estimated_df,food_nutrients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_demographic_df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't work because the information fdc_id is missing because the computation take too long\n",
    "calculate_nutrient_per_day_per_person(255,\"energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = [\"sandwich\",\"lettuce\",\"cheese\"]\n",
    "\n",
    "find_food(test3, food_name_df, DIC_SCORE, verb = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
