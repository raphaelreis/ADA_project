{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from IPython.core.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUNNHUMBY_PATH = '../data/dunnhumby - The Complete Journey CSV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ymentha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ymentha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "STOP_WORDS = list(set(stopwords.words('english')))\n",
    "STOP_WORDS.append('NFS')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "food = wn.synset('food.n.02')\n",
    "FOOD_WORDS = list(set([w for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual addition of words that we want to ignore to the Stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = [\"added\",\"ns\",\"made\",\"eaten\",\"type\",\"all\",\"as\",\"to\",\"of\"]\n",
    "STOP_WORDS.append(to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(str1): \n",
    "    \"\"\"\n",
    "    parses the string in a list of string (words) with all type of separators thanks to regexes\n",
    "    \"\"\"\n",
    "    #matches any separator and any whitespace and transforms to mathc to lower case\n",
    "    str1 = list(filter(None,re.split(\"[\\s;&@\\/:,\\*\\.\\(\\)\\{\\}\\\\-%\\\"\\'0-9\\_]\",str1)))\n",
    "    #remove duplicate word, as there are many\n",
    "    str1 = list(dict.fromkeys(str1))\n",
    "    str1 = [i.lower() for i in str1 if not i in STOP_WORDS]\n",
    "    str1 = [to_transform[i] if i in to_transform else i for i in str1]\n",
    "    \n",
    "    return str1\n",
    "\n",
    "def trim_nutrient_name(str1):\n",
    "    \"\"\"\n",
    "    simplifies the names of the nutrients for easier access afterwards\n",
    "    \"\"\"\n",
    "    #matches any separator and any whitespace and transforms to match to lower case\n",
    "    #temp = temp.lower()\n",
    "    temp = list(filter(None,re.split(\"[;&@\\/:,\\*\\.\\(\\)\\{\\}\\\\%\\\"\\']\",str1)))\n",
    "    #remove duplicate word, as there are many\n",
    "    temp = [i for i in temp if not i in STOP_WORDS]\n",
    "    if(temp[0] == \"fatty acids\"):\n",
    "        return str.strip(temp[0] + temp[1])\n",
    "    else:\n",
    "        return str.strip(temp[0])\n",
    "\n",
    "def get_amount(to_convert):\n",
    "    \"\"\"Returns the amount of a nutrient by taking into account the specified unit\n",
    "    \"\"\"\n",
    "    if(to_convert.unit_name == \"UG\"):\n",
    "        return to_convert.amount * 1e-6\n",
    "    elif(to_convert.unit_name == \"MG\"):\n",
    "        return to_convert.amount * 1e-3\n",
    "    else:\n",
    "        return to_convert.amount\n",
    "    \n",
    "def normalize_text(str1):\n",
    "    \"\"\"\n",
    "    simplifies the names of the foods for easier access afterwards\n",
    "    \"\"\"\n",
    "    #matches any separator and any whitespace and transforms to mathc to lower case\n",
    "    temp = re.sub(\"[;&@\\/:,\\*\\.\\(\\)\\{\\}\\\\%\\\"\\']\", ' ', str1)\n",
    "    temp = temp.lower()\n",
    "    words = temp.split()\n",
    "    words = [i for i in words if not i in STOP_WORDS]\n",
    "    temp = \" \".join(sorted(set(words), key=words.index))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df =  pd.read_csv(os.path.join(DUNNHUMBY_PATH,\"product.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>MANUFACTURER</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>COMMODITY_DESC</th>\n",
       "      <th>SUB_COMMODITY_DESC</th>\n",
       "      <th>CURR_SIZE_OF_PRODUCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>25671</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>FRZN ICE</td>\n",
       "      <td>ICE - CRUSHED/CUBED</td>\n",
       "      <td>22 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>26081</td>\n",
       "      <td>2</td>\n",
       "      <td>MISC. TRANS.</td>\n",
       "      <td>National</td>\n",
       "      <td>NO COMMODITY DESCRIPTION</td>\n",
       "      <td>NO SUBCOMMODITY DESCRIPTION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26093</td>\n",
       "      <td>69</td>\n",
       "      <td>PASTRY</td>\n",
       "      <td>Private</td>\n",
       "      <td>BREAD</td>\n",
       "      <td>BREAD:ITALIAN/FRENCH</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID  MANUFACTURER    DEPARTMENT     BRAND            COMMODITY_DESC  \\\n",
       "0       25671             2       GROCERY  National                  FRZN ICE   \n",
       "1       26081             2  MISC. TRANS.  National  NO COMMODITY DESCRIPTION   \n",
       "2       26093            69        PASTRY   Private                     BREAD   \n",
       "\n",
       "            SUB_COMMODITY_DESC CURR_SIZE_OF_PRODUCT  \n",
       "0          ICE - CRUSHED/CUBED                22 LB  \n",
       "1  NO SUBCOMMODITY DESCRIPTION                       \n",
       "2         BREAD:ITALIAN/FRENCH                       "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We only take the categories which are food related, sorted manually the different departments_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_sorted = products_df.groupby('DEPARTMENT').count().sort_values(by = 'PRODUCT_ID',ascending = False)\n",
    "#NB: there are a few food in MISC. TRANS\n",
    "food_related = np.array(['NUTRITION','GROCERY','PASTRY','MEAT-PCKGD','SEAFOOD-PCKGD','PRODUCE','DELI','MEAT','SALAD BAR','GRO BAKERY','FROZEN GROCERY','SPIRITS','RESTAURANT',''])\n",
    "\n",
    "products_df = products_df[products_df.DEPARTMENT.isin(food_related)]\n",
    "\n",
    "#we put all the description in a ingredients column\n",
    "products_df['ingredients'] = products_df.COMMODITY_DESC + \" \" + products_df.SUB_COMMODITY_DESC\n",
    "products_df.drop([\"MANUFACTURER\",\"DEPARTMENT\",\"BRAND\",\"COMMODITY_DESC\",\"SUB_COMMODITY_DESC\"],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see words in the product dataset, we would like to write them out completely for clarity\n",
    "#TO ADD: SNKSCKYS/CRKR/CNDY\n",
    "to_transform = dict({\"frzn\":\"frozen\",\"refrgratd\":\"refrigerated\",\"brkfst\":\"breakfast\",\"whlsm\":\"wholesome\",\\\n",
    "                     \"crkr\":\"cracker\",\"cndy\":\"candy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.ingredients = products_df.ingredients.apply(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [frozen, ice, crushed, cubed]\n",
       "2                [bread, italian, french]\n",
       "3    [fruit, shelf, stable, apple, sauce]\n",
       "4             [cookies, cones, specialty]\n",
       "5          [spices, extracts, seasonings]\n",
       "Name: ingredients, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.ingredients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we now have an easily parseable format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloaded food nutrients data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ymentha/anaconda3/envs/ada/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dfList = {}\n",
    "for r, d, f in os.walk('../data/health'):\n",
    "    for file in f:\n",
    "        if '.csv' in file:\n",
    "            #print(file)\n",
    "            dfList[file] = pd.read_csv(os.path.join(r, file))\n",
    "            \n",
    "branded_food_df = dfList['branded_food.csv']\n",
    "\n",
    "#link the nutrient id with its name\n",
    "nutrient_df = dfList['nutrient.csv']\n",
    "\n",
    "#contains the food articles name and their id test commit\n",
    "food_df = dfList['food.csv']\n",
    "\n",
    "#contains the nutrients for each food article\n",
    "food_nutrients_df = dfList['food_nutrient.csv']\n",
    "\n",
    "# linke the food articles ids to their potential category\n",
    "food_category_df = dfList['food_category.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We drop useless columns_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns and rename to be more understandable\n",
    "food_nutrients_df = food_nutrients_df.drop([\"data_points\",\"min\",\"max\",\"median\",\"footnote\",\"min_year_acquired\",\"derivation_id\"],axis=1)\n",
    "\n",
    "nutrient_df = nutrient_df.drop([\"nutrient_nbr\",\"rank\"],axis=1)\n",
    "\n",
    "food_category_df.drop([\"code\"],axis=1,inplace=True)\n",
    "food_category_df.rename(columns={'id':'food_category_id','description':'category'},inplace= True)\n",
    "\n",
    "food_df.drop([\"publication_date\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out only the necessary food nutrients since we have 227, a lot of which aren't necessary to determine if a food is healthy\n",
    "list_relevant_nutrients = [\"Protein\", \"Total Carbohydrate\",\"Total lipid (fat)\",\"Sucrose\",\\\n",
    "                            \"Glucose (dextrose)\",\"Sugars, total including NLEA\",\"Fatty acids, total monounsaturated\",\\\n",
    "                            \"Fatty acids, total polyunsaturated\",\"Fatty acids, total trans\",\"Fatty acids, total saturated\",\"Cholesterol\",\\\n",
    "                            \"Vitamin E, added\",\"Vitamin K (phylloquinone)\",\"Vitamin B-12\",\"Vitamin B-6\",\\\n",
    "                            \"Vitamin E (label entry primarily)\",\"Vitamin E (alpha-tocopherol)\",\"Vitamin D\",\"Vitamin A, RAE\",\"Sodium, Na\",\\\n",
    "                            \"Total fat (NLEA)\",\"Fiber, total dietary\",\"Energy\",\"Carbohydrate, by summation\",\"Fructose\"]\n",
    "\n",
    "nutrient_df = nutrient_df[nutrient_df.name.isin(list_relevant_nutrients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_df.name = nutrient_df.name.apply(trim_nutrient_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>unit_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>Protein</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1004</td>\n",
       "      <td>Total lipid</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1008</td>\n",
       "      <td>Energy</td>\n",
       "      <td>KCAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1010</td>\n",
       "      <td>Sucrose</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id         name unit_name\n",
       "1  1003      Protein         G\n",
       "2  1004  Total lipid         G\n",
       "5  1008       Energy      KCAL\n",
       "7  1010      Sucrose         G"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrient_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fdc_id</th>\n",
       "      <th>nutrient_id</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2288167</td>\n",
       "      <td>336069</td>\n",
       "      <td>1003</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2288168</td>\n",
       "      <td>336069</td>\n",
       "      <td>1004</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2288169</td>\n",
       "      <td>336069</td>\n",
       "      <td>1005</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2288170</td>\n",
       "      <td>336069</td>\n",
       "      <td>1008</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2288171</td>\n",
       "      <td>336069</td>\n",
       "      <td>1018</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  fdc_id  nutrient_id  amount\n",
       "0  2288167  336069         1003    3.28\n",
       "1  2288168  336069         1004    1.91\n",
       "2  2288169  336069         1005    4.85\n",
       "3  2288170  336069         1008   50.00\n",
       "4  2288171  336069         1018    0.00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_nutrients_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Add the names of the nutrients to the nutrients per food_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nutrients_df = food_nutrients_df.join(nutrient_df.set_index('id'),on='nutrient_id',how='inner')\n",
    "\n",
    "#index the resulting table by multiindex: product id -> name of nutrients\n",
    "food_nutrients_df = food_nutrients_df.set_index(pd.MultiIndex.from_frame(food_nutrients_df[['fdc_id','name']]))\n",
    "#drop unnecessary columns \n",
    "food_nutrients_df = food_nutrients_df.drop([\"id\",\"fdc_id\",\"nutrient_id\",\"name\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136576, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_nutrients_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount       3.37\n",
       "unit_name       G\n",
       "Name: (336079, Protein), dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here is the result\n",
    "food_nutrients_df.iloc[10] #TOTRASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we show the food contents of corned beef, the format matches our needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We add the food category to food_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdc_id</th>\n",
       "      <th>data_type</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>336069</td>\n",
       "      <td>survey_fndds_food</td>\n",
       "      <td>Milk, NFS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>336070</td>\n",
       "      <td>survey_fndds_food</td>\n",
       "      <td>Milk, whole</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>336071</td>\n",
       "      <td>survey_fndds_food</td>\n",
       "      <td>Milk, low sodium, whole</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>336072</td>\n",
       "      <td>survey_fndds_food</td>\n",
       "      <td>Milk, calcium fortified, whole</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>336073</td>\n",
       "      <td>survey_fndds_food</td>\n",
       "      <td>Milk, calcium fortified, low fat (1%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fdc_id          data_type                            description category\n",
       "0  336069  survey_fndds_food                              Milk, NFS      NaN\n",
       "1  336070  survey_fndds_food                            Milk, whole      NaN\n",
       "2  336071  survey_fndds_food                Milk, low sodium, whole      NaN\n",
       "3  336072  survey_fndds_food         Milk, calcium fortified, whole      NaN\n",
       "4  336073  survey_fndds_food  Milk, calcium fortified, low fat (1%)      NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_df = food_df.join(food_category_df.set_index(\"food_category_id\"),on=\"food_category_id\",how=\"left\")\n",
    "food_df.drop([\"food_category_id\"],axis=1,inplace=True)\n",
    "food_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_information_df = food_nutrients_df.join(food_df.set_index(\"fdc_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a lot of categories are unfortunately missing from the governement database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_At this stage we have 3 dataframes from our additional dataset for nutrition:_\n",
    "- food_df = fdc_id vs name of food item (string)\n",
    "- food_name_df = fdc_id vs parsed food title (list of string)\n",
    "- food_nutrients_df = fdc_id vs nutrients contained (multiindex)\n",
    "- all_information_df = fdc_id, nutrients, data type, description and food category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_names_to_parse_df = food_df.copy()\n",
    "food_names_to_parse_df.description = food_names_to_parse_df.description.apply(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.description = food_df.description.apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We filter the words according to their importance: that is, a word is more important as it apears many times in both datasets: (Ex: 'orange' is more important than 'artificial'). The words occuring in only one dataset are of no importance. The rest of the algorithm follows the following pipeline:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"701px\" version=\"1.1\" width=\"771px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><g transform=\"translate(0.5,0.5)\"><path d=\"M 149.7 43.98 L 233.65 49.58\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 238.88 49.93 L 231.67 52.95 L 233.65 49.58 L 232.13 45.97 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 129.43 70.15 L 203.94 127.13\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 208.11 130.32 L 200.43 128.85 L 203.94 127.13 L 204.68 123.29 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"90\" cy=\"40\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(68.5,33.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"42\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 42px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">k words</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"21\" y=\"12\">k words</text></switch></g><path d=\"M 331.29 84.13 L 405.7 165.31\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 409.24 169.18 L 401.93 166.38 L 405.7 165.31 L 407.09 161.65 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 359.77 46.48 L 463.64 40.37\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 468.88 40.07 L 462.1 43.97 L 463.64 40.37 L 461.69 36.98 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"300\" cy=\"50\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(256.5,43.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"86\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 86px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">there is a match</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"43\" y=\"12\">there is a match</text></switch></g><path d=\"M 263 189.95 L 266.09 223.72\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 266.57 228.95 L 262.45 222.3 L 266.09 223.72 L 269.42 221.66 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"260\" cy=\"150\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(234.5,143.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"50\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 50px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">no match</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"25\" y=\"12\">no match</text></switch></g><path d=\"M 270 310 L 270 363.63\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 270 368.88 L 266.5 361.88 L 270 363.63 L 273.5 361.88 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"270\" cy=\"270\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(211.5,256.5)\"><switch><foreignObject height=\"26\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"116\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 116px; white-space: normal; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">erase least important word</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"58\" y=\"19\">erase least important word</text></switch></g><path d=\"M 223.68 384.57 L 121.86 328.53\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 117.26 325.99 L 125.08 326.3 L 121.86 328.53 L 121.71 332.44 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 273 449.95 L 276.09 483.72\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 276.57 488.95 L 272.45 482.3 L 276.09 483.72 L 279.42 481.66 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"270\" cy=\"410\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(236.5,403.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"67\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 68px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">(k - 1) words</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"34\" y=\"12\">(k - 1) words</text></switch></g><path d=\"M 70 260 Q 10 260 10 240 Q 10 220 5 220 Q 0 220 0 130 Q 0 40 23.63 40\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 28.88 40 L 21.88 43.5 L 23.63 40 L 21.88 36.5 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"70\" cy=\"300\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(42.5,293.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"55\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 56px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">(k - 1) != 0</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"28\" y=\"12\">(k - 1) != 0</text></switch></g><path d=\"M 255.63 566.55 L 223.53 614.7\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 220.62 619.07 L 221.59 611.3 L 223.53 614.7 L 227.42 615.19 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"280\" cy=\"530\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(262.5,523.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"34\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 34px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">k == 0</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"17\" y=\"12\">k == 0</text></switch></g><ellipse cx=\"220\" cy=\"660\" fill=\"#ff9999\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(167.5,653.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"104\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 104px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">Give up the sample</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"52\" y=\"12\">Give up the sample</text></switch></g><path d=\"M 583.67 57.89 L 643.96 77.99\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 648.94 79.65 L 641.19 80.75 L 643.96 77.99 L 643.41 74.11 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"530\" cy=\"40\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(490.5,33.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"78\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 78px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">1 single match</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"39\" y=\"12\">1 single match</text></switch></g><path d=\"M 454.6 236.76 L 504.54 266.72\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 509.04 269.42 L 501.24 268.82 L 504.54 266.72 L 504.84 262.82 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"410\" cy=\"210\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(384.5,203.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"50\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 51px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">&gt;1 match</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"25\" y=\"12\">&amp;gt;1 match</text></switch></g><path d=\"M 543.28 276.72 L 645.5 174.5\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 649.21 170.79 L 646.73 178.22 L 645.5 174.5 L 641.78 173.27 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 569.83 307.01 L 703.64 300.32\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 708.88 300.06 L 702.07 303.9 L 703.64 300.32 L 701.72 296.91 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"510\" cy=\"310\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(451.5,289.5)\"><switch><foreignObject height=\"40\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"116\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 116px; white-space: normal; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">Take the match which has the min number of words</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"58\" y=\"26\">Take the match which has the min number of words</text></switch></g><rect fill=\"#97d077\" height=\"80\" pointer-events=\"none\" stroke=\"#97d077\" width=\"80\" x=\"650\" y=\"40\"/><g transform=\"translate(673.5,73.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"32\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">return</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"16\" y=\"12\">return</text></switch></g><path d=\"M 220 620 L 220 620\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 220 620 L 220 620 L 220 620 L 220 620 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 667.05 171.65 L 687.41 125.82\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 689.55 121.02 L 689.9 128.84 L 687.41 125.82 L 683.5 126 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"650\" cy=\"210\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(610.5,203.5)\"><switch><foreignObject height=\"12\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"78\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 78px; white-space: nowrap; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\">1 single match</div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"39\" y=\"12\">1 single match</text></switch></g><path d=\"M 689.57 409.86 L 689.57 409.86\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 689.57 409.86 L 689.57 409.86 L 689.57 409.86 L 689.57 409.86 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 713.51 300.07 L 728.44 130.34\" fill=\"none\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><path d=\"M 728.9 125.11 L 731.78 132.39 L 728.44 130.34 L 724.8 131.78 Z\" fill=\"#000000\" pointer-events=\"none\" stroke=\"#000000\" stroke-miterlimit=\"10\"/><ellipse cx=\"710\" cy=\"340\" fill=\"#ffffff\" pointer-events=\"none\" rx=\"60\" ry=\"40\" stroke=\"#000000\"/><g transform=\"translate(651.5,319.5)\"><switch><foreignObject height=\"40\" pointer-events=\"all\" requiredFeatures=\"http://www.w3.org/TR/SVG11/feature#Extensibility\" style=\"overflow:visible;\" width=\"116\"><div style=\"display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 116px; white-space: normal; overflow-wrap: normal; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"display:inline-block;text-align:inherit;text-decoration:inherit;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span>Take the one with the least important extra words</span></div></div></foreignObject><text fill=\"#000000\" font-family=\"Helvetica\" font-size=\"12px\" text-anchor=\"middle\" x=\"58\" y=\"26\">[Not supported by viewer]</text></switch></g></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(filename='untitled2.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_allwords(serie):\n",
    "    \"\"\"\n",
    "    serie: serie containing lists of words\n",
    "    return a dataframe containing\n",
    "      - column name: name of the unique articles found in the lists of the serie\n",
    "      - column count: how many times they appear in the serie\n",
    "    \"\"\"\n",
    "    allwords = np.concatenate(serie.ravel())\n",
    "    allwords = pd.Series(allwords)\n",
    "    allwords = pd.DataFrame(allwords,columns= [\"name\"])\n",
    "    allwords.reset_index(inplace = True)\n",
    "    allwords.rename(columns = {'index':'number'},inplace = True)\n",
    "    allwords = allwords.groupby('name').count().sort_values(by = 'number',ascending = False)\n",
    "    return allwords.reset_index()\n",
    "\n",
    "#all words present in the nutrition dataset\n",
    "all_words_nutrition = get_allwords(food_names_to_parse_df.description)\n",
    "\n",
    "#all words present in the product dataset\n",
    "all_words_supermarket = get_allwords(products_df.ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner merge between the 2 sets of words:\n",
    "\n",
    "_we check which words occur in both dataframes: only these words will have importance in determining the type of food article we are dealing with. Of course, if no words are known from the nutrition dataset, the sample is not taken into account._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = pd.merge(all_words_supermarket,all_words_nutrition,left_on = 'name',right_on = 'name',suffixes=('_supermarket', '_nutrition'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>number_supermarket</th>\n",
       "      <th>number_nutrition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>frozen</td>\n",
       "      <td>5755</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>snacks</td>\n",
       "      <td>3178</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>meat</td>\n",
       "      <td>3090</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dry</td>\n",
       "      <td>2991</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>premium</td>\n",
       "      <td>2423</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>cheese</td>\n",
       "      <td>2373</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>soft</td>\n",
       "      <td>2175</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>vegetables</td>\n",
       "      <td>2056</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>refrigerated</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>baked</td>\n",
       "      <td>1990</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  number_supermarket  number_nutrition\n",
       "0        frozen                5755               455\n",
       "1        snacks                3178                26\n",
       "2          meat                3090               405\n",
       "3           dry                2991               177\n",
       "4       premium                2423                31\n",
       "5        cheese                2373               545\n",
       "6          soft                2175                66\n",
       "7    vegetables                2056               458\n",
       "8  refrigerated                2010                 3\n",
       "9         baked                1990               449"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(common_words.size)\n",
    "common_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Manual check to see which words occur in which dataset\n",
    "print('chocolate' in all_words_nutrition.name.values)\n",
    "print('chocolate' in all_words_supermarket.name.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble them together (and pray your god)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-299-dddc4ee49455>, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-299-dddc4ee49455>\"\u001b[0;36m, line \u001b[0;32m57\u001b[0m\n\u001b[0;31m    importance = [ for i in test]\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_matches(test):\n",
    "    \"\"\"\n",
    "    test = list of strings to test\n",
    "    food_list: pandas dataframe linking the food article/id to the lists of words of its name\n",
    "    return all the articles whose words contain all of the words of test\n",
    "    \"\"\"\n",
    "    res =[]\n",
    "    for row in food_list.description:\n",
    "        if all(el in test and len(test) == len(row.split()) for el in row.split()):\n",
    "            res.append(row)\n",
    "    return res\n",
    "     \n",
    "def construct_dic_score(common_w = common_words):\n",
    "    \n",
    "    \"\"\"\n",
    "    common_w: dataframe containing the common names btwn products and nutrition\n",
    "    In order to give a score to a word, the priority is to check if it is present in the ntds list. If it is,\n",
    "    it gets a score of 1.\n",
    "    The rest of the score is a max-normalized ratio of the occurence in the product dataset.\n",
    "    \n",
    "    return a dic where each of these common names + food_words have their score linked\n",
    "    \"\"\"\n",
    "    common_w = common_w.copy()\n",
    "    maxo = common_w.number_supermarket.max()\n",
    "    common_w.number_supermarket = common_w.number_supermarket / maxo\n",
    "    common_w.drop(columns= [\"number_nutrition\"],axis = 1,inplace = True)\n",
    "\n",
    "    food_word_df = pd.DataFrame(columns = common_w.columns)\n",
    "    food_word_df.name = pd.Series(FOOD_WORDS)\n",
    "\n",
    "    food_word_df.name = food_word_df.name.apply(parse)\n",
    "    food_word_df = food_word_df.explode('name')\n",
    "    food_word_df.drop_duplicates(inplace = True)\n",
    "    food_word_df.fillna(1,inplace = True)\n",
    "\n",
    "    dic_score = pd.concat([food_word_df,dic_imp])\n",
    "    dic_score = final_df.rename(columns = {\"number_supermarket\":\"score\"})\n",
    "    dic_score = final_df.groupby(\"name\").sum()\n",
    "    dic_score.sort_values('score',ascending = False)\n",
    "    1/0\n",
    "    dic_score = pd.Series(dic_score.score.values,index = df.name).to_dict()\n",
    "    return dic_score\n",
    "    \n",
    "def find_food(test,food_list, dic_score):\n",
    "    \"\"\"\n",
    "    implementation of the graphic above\n",
    "    test = list of strings to test\n",
    "    food_list: pandas dataframe linking the food article/id to the lists of words of its name\n",
    "    return the best article\n",
    "    \"\"\"\n",
    "    if len(test) == 0:\n",
    "        #give up the sample\n",
    "        return 0 #dummy\n",
    "    \n",
    "    matches = get_matches(test,food_list)\n",
    "    if len(matches) == 0:\n",
    "        importance = [ for i in test]\n",
    "        mino = np.min(importance)\n",
    "        test = [i for i in test if i != mino]\n",
    "        return find_food(test,food_list)\n",
    "    elif len(matches) == 1:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        sizes = [len(i) for i in matches]\n",
    "        minsize = np.min(sizes)\n",
    "        minsizes = [i for i in matches if len(i) == minsize]\n",
    "        if len(minsizes) == 1:\n",
    "            return minsizes[0]\n",
    "        else:\n",
    "            importances = [np.sum([get_importance(j) for j in trial]) for trial in minsizes]\n",
    "            armin_imp = np.argmin(importances)\n",
    "            return importances[armin_imp]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.113640312771503}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = DIC_SCORE.get(\"duck\")\n",
    "DIC_SCORE[\"cake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = ['vanilla','creamy','swiss','miss','pudding','24','oz']\n",
    "DIC_SCORE = construct_dic_score(common_words)\n",
    "#find_food(test1,food_df,DIC_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_food_naive(test,food_list):\n",
    "    \"\"\"\n",
    "    food_list: pandas dataframe linking the food article/id id to the lists of words of its name\n",
    "    test: list of strings you want to have an id for\n",
    "    return the corresponding food indx\n",
    "    \"\"\"\n",
    "    #TODO: improve the non unique max\n",
    "    scores = [get_score(test,i) for i in food_list.description]\n",
    "    maxo = np.max(scores)\n",
    "    if len([1 for x in scores if x == maxo]) > 1:\n",
    "        print(\"Multiple maximums!\")\n",
    "    armax = np.argmax(scores)\n",
    "    print('result: ',food_list.description[armax])\n",
    "    return food_list.fdc_id[armax]\n",
    "\n",
    "def get_score(test,trial):\n",
    "    \"\"\"\n",
    "    test: the list of strings you're trying to classify\n",
    "    trial: the list you want the score for\n",
    "    return the score of matching\n",
    "    \"\"\"\n",
    "    return np.sum([1 for i in test if i in trial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO\n",
    "test1 = ['vanilla','creamy','swiss','miss','pudding','24','oz']\n",
    "test2 = ['libbys']\n",
    "get_matches(test1,food_df)\n",
    "#food_df.description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple maximums!\n",
      "result:  pudding fruit vanilla wafers\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_matches() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-264-28fe2c4c14c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## test1 = ['vanilla','swiss','miss','pudding','24','oz']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_food_naive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfood_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfind_food\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfood_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-256-9aa7038a873d>\u001b[0m in \u001b[0;36mfind_food\u001b[0;34m(test, food_list)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#dummy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfood_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_matches() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "## test1 = ['vanilla','swiss','miss','pudding','24','oz']\n",
    "print(find_food_naive(test1,food_df),find_food(test1,food_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: put name and food category into gov database??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'shrimp' in k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
